---
title: "Supplementary material, code, and tables for: Inconsistent shifts in warming and temperature variability negatively impact avian fitness."
author:
  - Conor C. Taff
  - J. Ryan Shipley
header-includes:
fontsize: 12pt
output: 
  bookdown::html_document2:
      number_sections: FALSE
      toc: TRUE
---

# **Full Analysis Script**

This script completes all analyses and produces all figures reported in the main text and supplement. Complete tables and additional plots that were not part of the main text are included here for reference. Annotation is included with each code block. Fully reproducing the output will require accessing the publicly available data available from resources indicated in the manuscript text and acquiring an API key to access historical weather data. Saved output for most code chunks is included in the repository (e.g., fit models, saved figure objects, etc). These outputs can be loaded and manipulated without needing to acquire the publicly available raw data.

This document isn't really meant to be knitted, but to help with organization, related blocks of code are stored in separate named chunks that should be run in order.

The initial code chunks load and wrangle data and set up options to be used later. Summary figures showing the distribution of data are created.

```{r setup-supp, include = FALSE, message = FALSE, warning = FALSE, echo = FALSE}
# Load packages ----
    pacman::p_load(tidyverse, here, sjPlot, maps, mapproj, rnoaa, viridis, lubridate, sf,
                   rnaturalearth, ggpubr, ggridges, ncdf4, raster, gganimate, gifski, stars, lme4,
                   lmerTest, mixtools, tictoc, data.table, cowplot, diptest, zoo, weathercan,
                   elevatr, mgcv, tidymv, mgcViz, svglite, plyr)

# General settings for later ----
# Set some colors or options that are used throughout code
      a_cav_color <- "darkred"
      a_cup_color <- "coral1"
      n_cav_color <- "darkblue"
      n_cup_color <- "lightblue"
      
# Projection code for Abers equal area. Many objects are transformed to this projection later on.
      proj_code <- 5070   
      
# This runs all the blocks of code that are normally skipped because they take a long time. 
      run_data_import <- "no"         # takes a few minutes, not too bad
      run_weather_download <- "no"    # takes a very long time
      run_historic_snaps <- "no"    # takes a long time
      run_anomaly_process <- "no"
```

```{r modify-functions, include = FALSE, message = FALSE, warning = FALSE, echo = FALSE}

# later I'm using the get_gam_predictions function from the tidymv package, but it doesn't have an easy way to get point estimates at specific values.
# I modified the source function here slightly so that I can specify values rather than a sequence with a certain number of intervals

get_gam_predictions2 <- function (model, series, series_length = 25, series_start = -3, series_end = 3, series_jump = 0.1, conditions = NULL, 
                                  exclude_random = TRUE, exclude_terms = NULL, split = NULL, 
                                  sep = "\\.", time_series, transform = NULL, ci_z = 1.96, 
                                  .comparison = NULL) 
{
    if (!missing(time_series)) {
        warning("The time_series argument has been deprecated and will be removed in the future. Please use `series` instead.")
        series_q = dplyr::enquo(time_series)
    }
    else {
        time_series = NULL
        series_q <- dplyr::enquo(series)
    }
    .comparison_q <- dplyr::enquo(.comparison)
    if (!is.null(model$dinfo) && (exclude_random || !is.null(exclude_terms))) {
        stop("Excluding random effects and/or terms is not currently supported with discretised models (fitted with discrete = TRUE). Please, set 'exclude_random' to FALSE and/or 'exclude_terms' to NULL.")
    }
    series_name <- rlang::quo_name(series_q)
    outcome_q <- model$formula[[2]]
    cond_terms <- NULL
    if (!is.null(conditions)) {
        for (cond_i in 1:length(conditions)) {
            cond_term <- as.character(rlang::quo_get_expr(conditions[[cond_i]])[2])
            cond_terms <- c(cond_terms, cond_term)
        }
    }
    if (!(rlang::quo_is_null(.comparison_q))) {
        cond_terms <- c(cond_terms, rlang::as_name(.comparison_q))
    }
    random_effects <- list()
    random_effects_terms <- NULL
    re_term <- NULL
    if (exclude_random == TRUE) {
        for (i in 1:length(model[["smooth"]])) {
            smooth_term <- model[["smooth"]][[i]][["term"]][[1]]
            smooth_class <- attr(model$smooth[[i]], "class")[1]
            if (smooth_class == "fs.interaction" && !(smooth_term %in% 
                                                      cond_terms)) {
                random_effects <- c(random_effects, list(model$smooth[[i]]$label))
                random_effects_terms <- c(random_effects_terms, 
                                          model$smooth[[i]]$fterm)
            }
            if (smooth_class == "random.effect" && !(smooth_term %in% 
                                                     cond_terms)) {
                random_effects <- c(random_effects, list(model[["smooth"]][[i]]$label))
                random_effects_terms <- c(random_effects_terms, 
                                          model$smooth[[i]]$term)
                re_term <- c(re_term, model$smooth[[i]]$term)
            }
        }
    }
    if (exclude_random) {
        if (rlang::is_empty(random_effects)) {
            exclude_random_effects <- as.null()
        }
        else {
            exclude_random_effects <- random_effects
        }
    }
    else {
        exclude_random_effects <- as.null()
    }
    exclude_smooths <- as.null()
    excluded_terms <- as.null()
    for (smooth in 1:length(model[["smooth"]])) {
        smooth_class <- attr(model$smooth[[smooth]], "class")[1]
        smooth_term <- model[["smooth"]][[smooth]][["term"]][[1]]
        if (smooth_class == "random.effect") {
            exclude_smooths <- exclude_smooths
            excluded_terms <- excluded_terms
        }
        else if (smooth_term != series_name && !(smooth_term %in% 
                                                 cond_terms)) {
            excluded_terms <- c(excluded_terms, smooth_term)
            smooth_label <- model[["smooth"]][[smooth]][["label"]]
            exclude_smooths <- c(exclude_smooths, smooth_label)
        }
        else if (smooth_class == "tensor.smooth") {
            smooth_term <- model[["smooth"]][[smooth]][["term"]][[2]]
            excluded_terms <- c(excluded_terms, smooth_term)
            smooth_label <- model[["smooth"]][[smooth]][["label"]]
            exclude_smooths <- c(exclude_smooths, smooth_label)
        }
    }
    excluded <- as.null()
    if (!is.null(exclude_terms)) {
        for (term in 1:length(exclude_terms)) {
            for (label in 1:length(model[["smooth"]])) {
                smooth_label <- model[["smooth"]][[label]][["label"]]
                if (smooth_label == exclude_terms[term]) {
                    smooth_term <- model[["smooth"]][[label]][["term"]]
                    if (!(smooth_term %in% cond_terms)) {
                        if (length(smooth_term) > 1) {
                            smooth_term_2 <- model[["smooth"]][[label]][["term"]][[2]]
                            excluded <- c(excluded, smooth_term_2)
                        }
                    }
                }
            }
        }
    }
    exclude_these <- c(exclude_random_effects, exclude_smooths, 
                       exclude_terms)
    var_list <- list()
    for (var in 1:length(model[["var.summary"]])) {
        var_class <- class(model[["var.summary"]][[var]])
        if (var_class == "numeric") {
            if (names(model[["var.summary"]][var]) %in% c(random_effects_terms, 
                                                          excluded_terms, excluded)) {
                var_values <- model[["var.summary"]][[var]][[1]]
            }
            else {
                var_values <- seq(series_start, series_end, series_jump)
            }
        }
        else if (var_class == "factor") {
            if (names(model[["var.summary"]][var]) %in% c(random_effects_terms, 
                                                          excluded_terms, excluded)) {
                var_values <- model[["var.summary"]][[var]][[1]]
            }
            else {
                var_values <- levels(model[["var.summary"]][[var]])
            }
        }
        var_values_list <- list(var_values)
        names(var_values_list)[[1]] <- names(model[["var.summary"]][var])
        var_list <- c(var_list, var_values_list)
    }
    fitted_df <- expand.grid(var_list)
    if ("(AR.start)" %in% colnames(fitted_df)) {
        fitted_df$`(AR.start)` <- NULL
    }
    predicted <- stats::predict(model, fitted_df, se.fit = TRUE, 
                                exclude = exclude_these)
    predicted_tbl <- cbind(fitted_df, predicted) %>% dplyr::mutate(CI_upper = fit + 
                                                                       ci_z * se.fit, CI_lower = fit - ci_z * se.fit)
    if (!is.null(transform)) {
        trans_fun <- transform
        predicted_tbl$CI_upper <- trans_fun(predicted_tbl$CI_upper)
        predicted_tbl$CI_lower <- trans_fun(predicted_tbl$CI_lower)
        predicted_tbl$fit <- trans_fun(predicted_tbl$fit)
    }
    predicted_tbl <- predicted_tbl %>% dplyr::rename(`:=`(!!rlang::quo_name(outcome_q), 
                                                          fit), SE = se.fit)
    if (!is.null(exclude_random_effects)) {
        for (term in 1:length(random_effects_terms)) {
            if (random_effects_terms[term] %in% re_term) {
                random_effects_terms <- random_effects_terms[-term]
            }
        }
        predicted_tbl <- predicted_tbl %>% dplyr::select(-dplyr::one_of(random_effects_terms)) %>% 
            unique()
    }
    if (!is.null(exclude_smooths)) {
        for (term in 1:length(excluded_terms)) {
            if (excluded_terms[term] %in% re_term) {
                excluded_terms <- excluded_terms[-term]
            }
        }
        predicted_tbl <- predicted_tbl %>% dplyr::select(-dplyr::one_of(excluded_terms)) %>% 
            unique()
    }
    if (!is.null(excluded)) {
        predicted_tbl <- predicted_tbl %>% dplyr::select(-dplyr::one_of(excluded)) %>% 
            unique()
    }
    if (!is.null(split)) {
        for (i in 1:length(split)) {
            predicted_tbl <- tidyr::separate(data = predicted_tbl, 
                                             col = names(split)[i], into = split[[i]], sep = sep)
        }
    }
    if (!is.null(conditions)) {
        predicted_tbl <- predicted_tbl %>% dplyr::filter(!!!conditions)
    }
    if (ncol(predicted_tbl) > 5) {
        predicted_tbl <- tidyr::unite(predicted_tbl, ".idx", 
                                      c(-CI_lower, -CI_upper, -SE, -!!rlang::quo_name(outcome_q), 
                                        -!!rlang::quo_name(series_q)), remove = FALSE) %>% 
            dplyr::mutate(.idx = as.numeric(as.factor(.idx)))
    }
    return(predicted_tbl)
}


```

```{r load-map, fig.width = 8, fig.height = 3, message = FALSE, warning = FALSE, echo = FALSE}
# Get map ----
      #us_map <- map_data(database = "world", regions = c("usa", "canada", "mexico")) #old
      namer <- ne_countries(continent = "North America", scale = 'medium', returnclass = "sf")
      
      # Save a version in the original projection
        namer_o <- namer

      # Crop to these limits    
        namer <- st_crop(namer, xmin = -135, xmax = -50, ymin = 20, ymax = 65)
      
      # Change to Abers equal area projection
        namer <- st_transform(namer, proj_code)
      
# Make hexagon grid ----
    # Make a box for the grid to be drawn within (larger than extent of data)   
        # Limits
          x_lo <- -135
          x_hi <- -55
          y_lo <- 10
          y_hi <- 65
        # Polygon drawn from limits  
          sfc <- st_sfc(st_polygon(list(rbind(c(x_lo, y_lo), c(x_hi, y_lo),
                                              c(x_hi, y_hi), c(x_lo, y_hi),
                                              c(x_lo, y_lo)))))
       # set to original map download crs
          sfc <- st_set_crs(sfc, st_crs(namer_o))
        # Set the crs to albers equal area projection
          sfc_alb <- st_transform(sfc, proj_code)
      
        # make a smaller box where I want to actual draw the plots
            x_lo <- -120
            x_hi <- -70
            y_lo <- 20
            y_hi <- 58
            sfc2 <- st_sfc(st_polygon(list(rbind(c(x_lo, y_lo), c(x_hi, y_lo),
                                                c(x_hi, y_hi), c(x_lo, y_hi),
                                                c(x_lo, y_lo)))))
          # set to original crs
            sfc2 <- st_set_crs(sfc2, st_crs(namer_o))
          # Transform this box to Albers equal area CRS  
            sfc2 <- st_transform(sfc2, proj_code)
          
          # Extract the bounding box in alber's CRS    
            bb <- st_bbox(sfc2)
      
      #Make hexagonal grids with an equal area in each grid. 
            #Albers units in is meters, so the cell size creates grids with area = 40000 square km  
            grid_m <- st_make_grid(sfc_alb, cellsize = 214914, square = FALSE)
      
      # Make plot for the grid with limits set by coord_sf and bounding box above
          p_map  <- ggplot() + geom_sf(data = namer, fill = "gray75") +
            coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
            theme_bw() +
            ylab("Latitude") + xlab("Longitude") 
          p_grid2 <- p_map + geom_sf(data = grid_m, fill = NA) +
            coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"]))
          
      # Proceeding on from here using this grid size
          geometry <- grid_m
          grid <- st_sf(geometry)
          grid$id <- as.factor(seq(1:nrow(grid)))
          grid <- grid[1:(nrow(grid) - 1), ]
          #colnames(grid) <- c("geometry", "id")
          #st_geometry(grid) <- "geometry"
          #grid <- st_cast(grid, "GEOMETRY")    
```

```{r load-data, message = FALSE, warning = FALSE, echo = FALSE}
## Load in data from nestwatch, martinwatch, and project nestwatch
# Because raw data needs to be accessed with a datasharing agreement, it is not included in the repository, but can be obtained
# from each of the community science projects directly.
# The saved output of this loading and the cleaning in the next chunk are stored and loaded so it is not run each time.
# This chunk is reading in data and doing a little bit of cleaning/manipulation that is specific to each dataset then merging them.
# More general cleaning is done in the next chunk.

# to run again change 'run_this' to "yes"; otherwise used cached outputs
  if(run_data_import == "yes"){
      # Read in nestwatch data ----
          d <- read.csv(here::here("1_raw_data/nestwatch_raw_data.csv"))
          colnames(d) <- c("loc_id", "latitude", "longitude", "subnat_code", "attempt_id",
                           "proj_period_id", "loc_id_1", "species_code", "outcome_code_list",
                           "first_lay_dt", "hatch_dt", "fledge_dt", "clutch_host_atleast",
                           "young_host_atleast", "young_fled_atleast", "eggs_host_unh_atleast")
        
          d$year <- as.numeric(substr(d$proj_period_id, 4, 7))
          d$source <- "NestWatch"
          
          d$lay <- as.POSIXct(d$first_lay_dt, format = "%d%b%y")
          d$hatch <- as.POSIXct(d$hatch_dt, format = "%d%b%y")
          d$fledge <- as.POSIXct(d$fledge_dt, format = "%d%b%y")
          d$lay_doy <- yday(d$lay)
          d$hatch_doy <- yday(d$hatch)
          d$fled_doy <- yday(d$fledge)
          d$first_egg_error <- NA
          
          #d <- subset(d, d$year > 1995)
        
      # Read in martinwatch data ----
          # This version is slightly modified with two additional columns where I have corrected formatting issues on the date field
            # manually. No changes to actual data values have been made from the original.
            # Values with 0.5 in date are because it is an average of early/late estimate.
              mw <- read.csv(here::here("1_raw_data/martinwatch_mod_data.csv"))
              colnames(mw) <- c("attempt_id", "zip", "n_yr_report", "first_egg_dt", "clutch_host_atleast",
                                "young_host_atleast", "young_fled_atleast", "cut", "cut2", "year", "latitude", "longitude",
                                "lay_doy", "first_egg_error")
            
        # Removing records with no date info
            mw <- subset(mw, mw$first_egg_dt != "")         #records with no date
            mw <- subset(mw, mw$first_egg_dt != "#DIV/0!")   #records where date was recorded as #/DIV0! in download. Presumably an old excel error.
        
        # adding in empty columns so it matches up with nestwatch data
            mw$subnat_code <- NA
            mw$loc_id <- NA
            mw$proj_period_id <- NA
            mw$loc_id_1 <- NA
            mw$species_code <- "purmar"
            mw$outcome_code_list <- NA
            mw$first_lay_dt <- NA
            mw$hatch_dt <- NA
            mw$fledge_dt <- NA
            mw$eggs_host_unh_atleast <- NA
            mw$source <- "MartinWatch"
            mw$lay <- NA
            mw$hatch <- NA
            mw$fledge <- NA
            mw$hatch_doy <- NA
            mw$fled_doy <- NA
            mw <- mw[, colnames(d)]
        
            d <- rbind(d, mw)
    
      # Read in project nestwatch data [Canada] ----
            nests <- read.delim(here::here("1_raw_data/canada_nestwatch_nests.txt"))
            checks <- read.delim(here::here("1_raw_data/canada_nestwatch_checks.txt"))    
            
            # Subset to nests that have a date for either laying or hatching (gets rid of most records)
                nests <- subset(nests, nests$lay_doy_calc > 0 | nests$hatch_doy_calc > 0)
            
            # subset the nest check data to just these nests
                checks <- subset(checks, checks$nest_id %in% nests$nest_id)
                
            # Change column types
                nests$latitude <- as.numeric(nests$latitude)
                nests$longitude <- as.numeric(nests$longitude)
                
            # Getting rid of some records that are way outside the geographic range we are looking at
                nests <- subset(nests, nests$longitude < -50)
                nests <- subset(nests, nests$latitude > 30)
                
           # Count how many nest checks there are for a given nest
        for(i in 1:nrow(nests)){
          nests$count[i] <- nrow(subset(checks, checks$nest_id == nests$nest_id[i]))
          #print(paste(i, " of ", nrow(nests)))
        }
        
      # Get rid of nests with no checks
          nests <- subset(nests, nests$count > 0)
          
      # summarize check info for each nest
          nests <- nests[, c("nest_id", "year", "species_code", "statprov_code", "comments_nestsite", 
                             "clutch_size_manual", "latitude", "longitude", "lay_doy_calc", "hatch_doy_calc", "fledge_doy_calc", "count")]
          
          for(i in 1:nrow(nests)){
            sub <- subset(checks, checks$nest_id == nests$nest_id[i])
            final <- subset(sub, sub$visit_id == 999)
            if(nrow(subset(sub, sub$visit_id == 999)) == 0){
              final <- sub[nrow(sub), ]
            }
            nests$max_eggs[i] <- max(as.numeric(subset(sub$eggs, sub$eggs != "NULL" & as.numeric(sub$eggs > -1))))
            nests$max_young[i] <- max(as.numeric(subset(sub$young, sub$young != "NULL")))
            nests$max_dead[i] <- max(as.numeric(subset(sub$deadyg, sub$deadyg != "NULL")))
            nests$stage_max[i] <- max(as.numeric(subset(sub$stage_code_calculated, sub$stage_code_calculated != "NULL")))
            nests$final_success_code[i] <- final$success_code_calculated
            nests$type_of_code[i] <- final$visit_id[1]
            #print(paste(i, " of ", nrow(nests)))
          }     
          
          # For cases with more young than eggs, replace clutch size with NA
            for(i in 1:nrow(nests)){
              if(nests$max_eggs[i] < nests$max_young[i]){nests$max_eggs[i] <- NA}
            }
          
          # Get rid of nests that only have 2 or fewer checks, can't be certain about them
            nests <- subset(nests, nests$count > 2)
            
          # Sub four letter codes for six letters that match nestwatch
            four <- unique(nests$species_code)
            six <- c("houfin", "prowar", "bkcchi", "treswa", "easblu", "easpho", "moudov", "amerob", "olsfly", "acafly", "wilfly", "leafly", "aldfly", "purmar", "barswa",
                     "poehud", "sitcan", "whbnut", "thrlud", "bewwre", "houwre", "norcar", "moublu", "saysay", "poegam", "vigswa")
            for(i in 1:length(four)){
              nests$species_code <- gsub(four[i], six[i], nests$species_code)
            }
          
          # Change columns to match nestwatch and martinwatch data
            nests$loc_id <- NA
            nests$subnat_code <- paste("CA", nests$statprov_code, sep = "-")
            nests$attempt_id <- nests$nest_id
            nests$proj_period_id <- NA
            nests$loc_id_1 <- NA
            nests$outcome_code_list <- NA
            nests$first_lay_dt <- NA
            nests$hatch_dt <- NA
            nests$fledge_dt <- NA
            nests$clutch_host_atleast <- nests$max_eggs
            nests$young_host_atleast <- nests$max_young
            nests$eggs_host_unh_atleast <- NA
            nests$source <- "ProjNestWatch"
            nests$lay <- NA
            nests$hatch <- NA
            nests$fledge <- NA
            nests$lay_doy <- nests$lay_doy_calc
            nests$hatch_doy <- nests$hatch_doy_calc
            nests$fled_doy <- nests$fledge_doy_calc
            nests$first_egg_error <- NA
            
            for(i in 1:nrow(nests)){
              if(nests$final_success_code[i] == 1){nests$young_fled_atleast[i] <- 0}
              if(nests$final_success_code[i] == 2){nests$young_fled_atleast[i] <- nests$max_young[i] - nests$max_dead[i]}
              if(nests$final_success_code[i] == 3){nests$young_fled_atleast[i] <- nests$max_young[i]}
              if(nests$final_success_code[i] == 0){nests$young_fled_atleast[i] <- NA}
            }
            
        # Nest codes for canada are basically 0 = unknonwn, 1 = failure, 2 = partial fledge, 3 = fledge    
            # Removing nests with unknown fate
              nests <- subset(nests, nests$final_success_code == 1 | nests$final_success_code == 2 | nests$final_success_code == 3)
              
              nests2 <- nests[, colnames(d)]
              nests2$lay_doy <- as.numeric(nests2$lay_doy)
              
        # Combine canada data with other data
              d <- rbind(d, nests2)
  }
```

```{r clean-data, message = FALSE, warning = FALSE, echo = FALSE}
# This is taking the input data from the last chunk and cleaning it by filtering in various ways
# The final output is saved at the end and reloaded, so this does not need to be run each time unless changes are made

# As above, data will need to be obtained from the community science projects first

# to run again change 'run_this' to "yes"
  if(run_data_import == "yes"){
    # Species group list info ----
        spp_list <- read.csv(here::here("1_raw_data/species_list.csv"))
        d <- join(d, spp_list, "species_code")
      
      # Dropping a few species that were in record but not worth saving
        d2 <- subset(d, d$exclude == "no")
      
      # Cutting out the small number of nests in alaska and mexico
        #d2 <- subset(d2, d2$longitude > -127 & d2$latitude > 22 & d2$longitude < -55)
        d2$plot_group <- factor(d2$plot_group, levels = c("Flycatchers", "Swallows",
                                                          "Swifts & Martins", "Bluebirds", "Chickadees", "Titmice & Nuthatches",
                                                          "Wrens", "Other Cavity-Nesters", "Other Cup-Nesters"))
        
      # count number of records for species
        sp_n <- data.frame(alpha4 = unique(d2$alpha4))
        for(i in 1:nrow(sp_n)){
          sub <- subset(d2, d2$alpha4 == sp_n$alpha4[i])
          sp_n$tot_count[i] <- nrow(sub)
        }
        d2 <- join(d2, sp_n, "alpha4")
        
      # drop species with < 300 total nest records
        d2 <- subset(d2, d2$tot_count > 500)
        
      # samples per group
        gr_n <- data.frame(plot_group = unique(d2$plot_group))
        for(i in 1:nrow(gr_n)){
          sub <- subset(d2, d2$plot_group == gr_n$plot_group[i])
          gr_n$count[i] <- nrow(sub)
        }  
        
      # It seems that european starlings and house sparrows are almost all 0 fledge, which I think means that poeple were destroying
        #the nests? That would make some sense if it is largely maintenance for bluebirds. Given that, lets take them out.
          d2 <- subset(d2, d2$alpha4 != "EUST" & d2$alpha4 != "HOSP")
          
      # categorize aerial + cavity
          d2$a_cav <- paste(d2$aerial, d2$cavity, sep = "_")
          colors <- data.frame(a_cav = c("no_yes", "yes_yes", "no_no", "yes_no"), pl_col = c(n_cav_color, a_cav_color, n_cup_color, a_cup_color))
          d2 <- join(d2, colors, "a_cav")
          d2$alpha4 <- as.factor(d2$alpha4)
          
        # round the latitude and longitude to speed up calculations, also I don't trust 5 digit accuracy in user submitted coordinates.     
          d2$latitude <- round(d2$latitude, 3)
          d2$longitude <- round(d2$longitude, 3)
          
      #drop some columns so we can keep track more easily
          d2 <- subset(d2, select = -c(outcome_code_list, proj_period_id, loc_id_1, first_lay_dt, hatch_dt, fledge_dt))
          
          d2$report_error <- dplyr::if_else (d2$clutch_host_atleast == d2$young_fled_atleast, 1, 0)
          
      # Add in a reporting check for what percent of nests from a location are reported as 100% fledged
               nw_quality <- d2 %>%
                               group_by(loc_id, year) %>%
                               dplyr::summarize(n = n(), fails = sum(report_error)) 
               nw_quality$loc_yr <- paste(nw_quality$loc_id, nw_quality$year, sep = "_")
               nw_quality$pct_full_fled <- nw_quality$fails / nw_quality$n
               
               d2$loc_yr <- paste(d2$loc_id, d2$year, sep = "_")
               nw_quality$site_n <- nw_quality$n
               d2 <- plyr::join(d2, nw_quality[, c("loc_yr", "site_n", "fails", "pct_full_fled")])
               
        # Consider excluding nests where a site has > n nests that all have perfect fledging success...unrealistic   
           
           

    # Clean data ----
      # Both of these large datasets have some uneven data entry. We can't check every single record, 
        # but we can remove entries with unlikely values. I'm doing this by just plotting each species distribution for 
        # lay date, clutch size, number fledged, and year then removing any obviously unrealistic numbers on a species by
        # species basis.
          
          # Filter out data with unrealistic breeding information. These decisions were made by looking at the raw plots.
          for(i in 1:nrow(d2)){
            # Lay dates
            if(is.na(d2$lay_doy[i]) == FALSE){
              if(d2$alpha4[i] == "AMRO" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BARS" & d2$lay_doy[i] < 65){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BCCH" & d2$lay_doy[i] < 55){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BHNU" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "CACH" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "CBCH" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "EABL" & d2$lay_doy[i] < 40){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "EAPH" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "HOWR" & d2$lay_doy[i] < 65){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "MOBL" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "OATI" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "PUMA" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "TRES" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "VGSW" & d2$lay_doy[i] < 60){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "WBNU" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "WEBL" & d2$lay_doy[i] < 50){d2$lay_doy[i] <- NA}
            }
            if(is.na(d2$lay_doy[i]) == FALSE){
              if(d2$alpha4[i] == "AMRO" & d2$lay_doy[i] > 225){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BARS" & d2$lay_doy[i] > 250){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BCCH" & d2$lay_doy[i] > 235){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "BHNU" & d2$lay_doy[i] > 150){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "CACH" & d2$lay_doy[i] > 215){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "CBCH" & d2$lay_doy[i] > 175){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "EABL" & d2$lay_doy[i] > 250){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "EAPH" & d2$lay_doy[i] > 210){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "HOWR" & d2$lay_doy[i] > 240){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "MOBL" & d2$lay_doy[i] > 220){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "OATI" & d2$lay_doy[i] > 160){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "PUMA" & d2$lay_doy[i] > 220){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "TRES" & d2$lay_doy[i] > 230){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "VGSW" & d2$lay_doy[i] > 220){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "WBNU" & d2$lay_doy[i] > 190){d2$lay_doy[i] <- NA}
              if(d2$alpha4[i] == "WEBL" & d2$lay_doy[i] > 230){d2$lay_doy[i] <- NA}
            }
            # Clutch size
            if(is.na(d2$clutch_host_atleast[i]) == FALSE){
              if(d2$alpha4[i] == "BEWR" & d2$clutch_host_atleast[i] > 10){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "CBCH" & d2$clutch_host_atleast[i] > 11){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "CACH" & d2$clutch_host_atleast[i] > 11){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "EABL" & d2$clutch_host_atleast[i] > 10){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "HOWR" & d2$clutch_host_atleast[i] > 11){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "MOBL" & d2$clutch_host_atleast[i] > 10){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "OATI" & d2$clutch_host_atleast[i] > 12){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "PUMA" & d2$clutch_host_atleast[i] > 11){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "TRES" & d2$clutch_host_atleast[i] > 12){d2$clutch_host_atleast[i] <- NA}
              if(d2$alpha4[i] == "WEBL" & d2$clutch_host_atleast[i] > 10){d2$clutch_host_atleast[i] <- NA}
            }
            # Number fledged
            if(is.na(d2$young_fled_atleast[i]) == FALSE){
              if(d2$alpha4[i] == "EABL" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "WEBL" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "HOWR" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "BCCH" & d2$young_fled_atleast[i] > 10){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "MOBL" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "PUMA" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
              if(d2$alpha4[i] == "TRES" & d2$young_fled_atleast[i] > 9){d2$young_fled_atleast[i] <- NA}
            }
          }
          
        # Some records list 0 clutch sizes. I guess these failed before any laying?? I am removing them.
          d2 <- subset(d2, d2$clutch_host_atleast > 0)
          
          
  }


```

```{r elton-traits, message = FALSE, warning = FALSE, echo = FALSE}
# Join the elton traits diet data to the breeding records. This only needs to be rerun if the blocks above are changed.
# I am also joining here the incubation period 
# This traits database did not really end up being used in the paper. It can be accessed from the elton traits website.

if(run_data_import == "yes"){
  #We could add some data from CLO on incubation periods to recover more hatch dates, all data is from BOW or CLO
          #maybe we should merge this before filtering so it saves processing time later on
          species_data <- read.csv(here::here("1_raw_data/species_data.csv"))
          
          #merge to tie the mean incubation and nest timing to species
          d2 <- merge(d2, species_data, by=c("alpha4"))
          
          #bring in the elton trait data
          trait_data <- read.csv(here::here("1_raw_data/elton_traits_1.csv"))
          
          #merge with the original database
          trait_data <- trait_data[, c("Scientific", "Diet.Inv", "Diet.Certainty", "ForStrat.aerial")]
                
          trait_data <- trait_data %>%
                                separate(Scientific, c("genus", "species"), " ")
          
          trait_data$genus[ trait_data$genus == "Parus"] <- "Poecile"
          trait_data$genus[ trait_data$genus == "Carpodacus"] <- "Haemorphus"
          
          d2 <- merge(d2, trait_data, by=c("genus", "species"), all.x=TRUE)
          
          #use ifelse to replace hatch dates that are missing or NA where a lay_date is known with the estimated incubation time for each species
          #d2$lay_doy <- as.numeric(d2$lay_doy)
            d2$hatch_doy <- ifelse(is.na(d2$hatch_doy), floor(d2$lay_doy + d2$incu_days), d2$hatch_doy)
          
          # Doing the reverse of above to calculate lay date for nests that have a known hatch date
            d2$lay_doy <- ifelse(is.na(d2$lay_doy), floor(d2$hatch_doy - d2$incu_days - d2$clutch_host_atleast), d2$lay_doy)

          #these values should be the same if we've dealt with NA's successfully, fortunately they are.  :) 
          summary(d2$lay_doy)
          summary(d2$hatch_doy)
          
          # Get rid of records with no date or location data
          d2 <- d2[!is.na(d2$hatch_doy),]
          d2 <- subset(d2, is.na(d2$latitude) == FALSE & is.na(d2$longitude) == FALSE)
          
          # Before 1995 there are never more than ~200 records in a year. Removing those from the dataset.
            d2 <- subset(d2, d2$year > 1994)
            
          # Remove records with unreliable or impossible fledging numbers
            d2 <- subset(d2, d2$young_fled_atleast > -1 & d2$young_fled_atleast < 15)
          
          
          # Save teh cleaned and merged data
            saveRDS(d2, here::here("6_saved_data_objects/clean_nest_data.rds"))
}

# Read in the raw data processed through the chunks above
  d2 <- readRDS(here::here("6_saved_data_objects/clean_nest_data.rds"))
```

```{r full-map, fig.width = 7, fig.height = 5.5, echo = FALSE, fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Number of breeding records included within each grid cell for all species and years from the combined datasets after filtering. A total of 301,514 records from 24 species are included from 1995 to 2020."}
# Convert data to an sf object for plotting
      dsf <- st_as_sf(d2, coords = c("longitude", "latitude"), crs = st_crs(namer_o))
      dsf <- st_transform(dsf, proj_code)
      
# joining the breeding data frame and grid together    
      n_in_g <- st_join(dsf, grid, join = st_intersects)
      g_by_n <- st_join(grid, dsf, join = st_intersects) 
      
# Summarize number of nests by grid
      n_total <- n_in_g %>%
        group_by(id) %>%
        dplyr::summarize(n = n(), lay = mean(lay_doy, na.rm = TRUE))
      n_extract <- st_drop_geometry(n_total)
      grid2 <- left_join(grid, n_extract, "id")
      grid2 <- subset(grid2, is.na(grid2$n) == FALSE)
      
# Make a map
      p_base <- ggplot(data = dsf) + geom_sf(data = namer, fill = "gray75") + 
          theme_bw() +
          scale_fill_viridis(alpha = 0.8, option = "cividis", trans = 'log10') + 
          xlab("Longitude") + ylab("Latitude") +
          theme(legend.position = "right") +
          theme(axis.title = element_text(size = 16)) +
          theme(legend.title = element_blank())
          
      
      p_all <- p_base + geom_sf(data = grid2, mapping = aes(fill = n)) +
        #ggtitle("311,872 breeding records for 24 species") +
        #guides(fill = FALSE) +
        coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"]))
      
    
      
      #p_all
      
      saveRDS(p_all, here::here("4_output_figures", "all_records.rds"))
      
```

```{r n-table, echo = FALSE, message = FALSE, warning = FALSE}
# make a simple table showing sample sizes
  dstab <- d2 %>%
    group_by(common_name, genus, species) %>%
    dplyr::summarize(n = n())

  dstab$sci_spp <- paste(dstab$genus, dstab$species, sep = " ")
  dstab <- dstab[, c("common_name", "sci_spp", "n")]
  
  saveRDS(dstab, here::here("4_output_figures", "spp_table.rds"))

  # kableExtra::kable(dstab, caption = "Total number of breeding records for each included species.",
  #       col.names = c("Common name", "Scientific name", "Records")) %>%
  #       kableExtra::column_spec(2, italic = TRUE) %>%
  #       kableExtra::kable_styling(position = "center", full_width = TRUE)
```

```{r add-elevation, message = FALSE, warning = FALSE, echo = FALSE}
  # # Convert points back to original projection to get elevations
  #   dsfo <- st_transform(dsf, st_crs(namer_o))
  # 
  # # access raster for this spatial extent
  #   dem <- get_elev_raster(grid2, z = 7, neg_to_na = TRUE, clip = "locations")
  #   saveRDS(dem, here::here("6_saved_data_objects/dem.rds"))
  #   dem <- readRDS(here::here("6_saved_data_objects/dem.rds"))
  # 
  #   dsfotest <- head(subset(dsfo, dsfo$source == "MartinWatch"), 20)
  #   dsfo2 <- get_elev_point(dsfotest)
  # 
  #   dsfo$elevation <- extract(dem, dsfo)
  #   dsfo <- st_transform(dsfo, st_crs(proj_code))

  # Writing the saved version to file
      # saveRDS(dsfo, here::here("6_saved_data_objects/records_with_elev.rds"))
      dsfo <- readRDS(here::here("6_saved_data_objects/records_with_elev.rds"))
      
```

```{r station-map, fig.width = 7, fig.height = 5.5, echo = FALSE, results = FALSE, fig.align = "center", message = FALSE, warning = FALSE, fig.cap = "Weather stations used to access historical temperature data. Individual points show station locations with data downloaded from NOAA (n = 2608) or Environment and Climate Change Canada (n = 1125). Stations that had at least 50 years of available data were included. Yellow hexagons show the spatial extent of the avian breeding records used in the analysis to illustrate how coverage of temperature data corresponds to the main dataset."}
# Plot NOAA + Canada stations ----
     # You need to get an API key to access the NOAA data. You can get one at this site
        # and plug it in here. https://www.ncdc.noaa.gov/cdo-web/token
        # The calls to NOAA won't work without this token.
            #options(noaakey = "ADD_YOUR_KEY")
     
     # GHCND is the daily summary data
          ncdc_locs(locationcategoryid = "CITY", sortfield = "name", sortorder = "desc", limit = 100)
          xx <- ncdc_locs(datasetid = "GHCND")
          ncdc_locs(locationcategoryid = "ST", limit = 52)
         
         station_data <- ghcnd_stations()

         station_data2 <- filter(station_data, first_year < 1950 & last_year > 2019 &
                                   latitude > 22 & latitude < 71 & longitude < -63 & longitude > -128)
         station_data3 <- filter(station_data2, element == "TMAX" | element == "TMIN" | element == "TAVG")
         
         #stations <- isd_stations()
         #df <- stations[complete.cases(stations$lat, stations$lon), ]
         #df <- df[df$lat != 0, ]
         

         sd3 <- st_as_sf(x = as.data.frame(station_data3), coords = c("longitude", "latitude"), crs = st_crs(namer_o))
         colnames(sd3)[1] <- "stn_id"
         sd3 <- st_transform(sd3, proj_code)
         sd4 <- st_join(sd3, grid, join = st_intersects)
         sd4 <- sd4[!duplicated(sd4$stn_id), c("stn_id", "id")]
         sd4$source <- "NOAA"
         
         
        # Add in Canadian stations
          stations$span <- stations$end - stations$start
          sid <- subset(stations, stations$interval == "day" & stations$span > 50)
          sid$stn_id <- sid$station_id
          sid2 <- st_as_sf(x = as.data.frame(sid), coords = c("lon", "lat"), crs = st_crs(namer_o))
          sid3 <- st_transform(sid2, proj_code)
          sid4 <- st_join(sid3, grid, join = st_intersects)
          sid4 <- sid4[!duplicated(sid4$stn_id), c("stn_id", "id")]
          sid4$source <- "Canada"
          
        # Join us and canada
          sd4 <- rbind(sd4, sid4)
         
         
         p_station <- ggplot() + 
           geom_sf(data = namer, fill = "gray75") + 
           geom_sf(data = grid2, fill = "yellow", alpha = .6) +
           geom_sf(data = sd4, color = "slateblue", alpha = 0.7, size = 0.6) +
           theme_bw() +
           xlab("Longitude") + ylab("Latitude")  +
           coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
           theme(axis.title = element_text(size = 16))
         
         #p_station
         
         saveRDS(p_station, here::here("4_output_figures", "stn_map.rds"))
```

## **Spring temperature and cold snap timing**

```{r get-temperature, echo = FALSE, message = FALSE, warning = FALSE}
# Download historic temperature ----
    # USA
    # This section downloads huge temperature database and takes a long time. Object is saved to reload below.
    # First for US then Canada then merged together.
      if(run_weather_download == "yes"){   
           temperature <- data.frame(station_id = NA, value = NA, date = as.Date("2025-01-01", "%Y-%m-%d"), reading = NA)
           
           sd3MAX <- subset(sd3, sd3$element == "TMAX")
           sd3MIN <- subset(sd3, sd3$element == "TMIN")
              
           for(i in 1:nrow(sd3MIN)){   
             stn <- ghcnd_search(sd3MIN$id[i], var = sd3MIN$element[i], refresh = TRUE)
             st2 <- as.data.frame(stn)
             st3 <- data.frame(station_id = st2[, 1], value = st2[, 2], date = st2[, 3], reading = sd3MIN$element[i])
             temperature <- rbind(temperature, st3)
             print(paste(i, "of", nrow(sd3MIN), sep = " "))
           }   
             
           temperature <- temperature[2:nrow(temperature), ]
           temperature$doy <- yday(temperature$date)
           temperature$year <- year(temperature$date)
           
           temp_max <- temperature
           
           t2 <- subset(temperature, temperature$doy > 90 & temperature$doy < 240 & temperature$year > 1940)
           
           # saveRDS(temperature, here::here("6_saved_data_objects/t_MIN.rds"), compress = TRUE)
           # saveRDS(t2, here::here("6_saved_data_objects/t_MIN_sub.rds"), compress = TRUE)
          
          tem <- readRDS(here::here("6_saved_data_objects/t_MAX.rds"))
        
 
    # CANADA
    # This also takes a long time to run and is saved
        for(i in 1:nrow(sid)){
          dl <- weather_dl(sid$station_id[i], interval = "day")
          if(i == 1){wcan <- dl}
          if(i > 1){wcan <- rbind(wcan, dl)}
          print(paste(i, " of ", nrow(sid)))
        }  
        wcan2 <- data.frame(station_id = wcan$station_id,
                            value = wcan$max_temp * 10,
                            date = wcan$date,
                            reading = "TMAX",
                            doy = yday(wcan$date),
                            year = year(wcan$date))
        wcan2 <- subset(wcan2, is.na(wcan2$value) == FALSE)
        
        wc2 <- subset(wcan2, wcan2$doy > 90 & wcan2$doy < 240 & wcan2$year > 1940)
        
        # saveRDS(wcan, here::here("6_saved_data_objects/canada_temp.rds"), compress = TRUE)
        # saveRDS(wc2, here::here("6_saved_data_objects/canada_max.rds"), compress = TRUE)
        
        can_tem <- readRDS(here::here("6_saved_data_objects/canada_max.rds"))
      
      
     
    # Join US & Canada. This is using max temperature.
      tem <- rbind(tem, can_tem)
      
    # save combined temperature  
      saveRDS(tem, here::here("6_saved_data_objects/combo_max_temp.rds"), compress = TRUE)
      tem <- readRDS(here::here("6_saved_data_objects/combo_max_temp.rds"))
      
      }
```

```{r compare-shift, echo = FALSE, message = FALSE, warning = FALSE}
# wrangle stations and temperature together
    sd5 <- sd4
    colnames(sd5)[1] <- "station_id"
    tem_delt <- tem %>%
      filter(year > 1950, year < 1980, doy > 60, doy < 240) %>%
      left_join(sd5, "station_id") %>%
      group_by(year, doy, id) %>%
      summarise(temperature = mean(value, na.rm = TRUE), n_stns = n())
    
    tem_delt2 <- tem_delt %>%
      group_by(id, doy) %>%
      summarise(temperature = mean(temperature, na.rm = TRUE))
    
    tem_now <- tem %>%
      filter(year > 2009, doy > 60, doy < 240) %>%
      left_join(sd5, "station_id") %>%
      group_by(year, doy, id) %>%
      summarise(temperature = mean(value, na.rm = TRUE), n_stns = n())
    
    tem_now2 <- tem_now %>%
      group_by(id, doy) %>%
      summarise(temperature = mean(temperature, na.rm = TRUE))
    
    lay_date <- n_in_g %>%
      group_by(id.y) %>%
      summarise(avg_lay = mean(lay_doy, na.rm = TRUE)) %>%
      st_drop_geometry()
    colnames(lay_date) <- c("id", "avg_lay")
    
    lay_date <- as.data.frame(subset(lay_date, lay_date$id %in% unique(tem_now2$id)))
    
    
    for(i in 1:nrow(lay_date)){
      sub <- subset(tem_now2, tem_now2$id == lay_date$id[i] & 
                      tem_now2$doy > lay_date$avg_lay[i] - 1 &
                      tem_now2$doy < lay_date$avg_lay[i] + 26)
      lay_date$avg_now_high[i] <- mean(sub$temperature / 10, na.rm = TRUE)
      
      sub2 <- subset(tem_delt2, tem_delt2$id == lay_date$id[i] &
                       tem_delt2$doy > lay_date$avg_lay[i] -1 &
                       tem_delt2$doy < lay_date$avg_lay[i] + 26 + 29)
      adv <- data.frame(advance = seq(0, 42, 1),
                        avg_high = NA)
      for(j in 1:nrow(adv)){
        subj <- subset(sub2, sub2$doy > lay_date$avg_lay[i] + adv$advance[j] -1 &
                         sub2$doy < lay_date$avg_lay[i] + adv$advance[j] + 26)
        adv$avg_high[j] <- mean(subj$temperature / 10, na.rm = TRUE)
        adv$start[j] <- lay_date$avg_lay[i] + adv$advance[j]
        adv$end[j] <- lay_date$avg_lay[i] + adv$advance[j] + 25
      }
      
      adv$dif <- adv$avg_high - lay_date$avg_now_high[i]
      
      lay_date$advance[i] <- which.min(abs(adv$dif))
    }
    
    lay_date <- na.omit(lay_date)
    
# next use advance date by grid to calculate the coldest and hottest 3-day temperature

```

```{r historic-snaps, echo = FALSE, message = FALSE, warning = FALSE}
# Determine cold snaps ----             
    # This is looping through every year and grid cell and figuring out the last 1/2/3 day cold snap where
      # maximum temperature didn't go above a threshold value of 18.5. It takes a long time to run so I have it saved and
      # loaded.
      # Heat waves are similar except are looking for 1/2/3 days where maximum temperature never goes below the threshold.
      # For cold snaps and heat waves, if there are none detected (NA) then it subs in the minimum or maximum value from the 10 closest years
      # for the same grid. This is to make sure those years still 'count'.
      # It currently runs at three temperature thresholds for cold and three for hot
          
          if(run_historic_snaps == "yes"){
          # Set up outside of the loop  
            tem_limit <- subset(tem, tem$doy < 240 & tem$doy > 60)
            colnames(tem_limit)[1] <- "stn_id"
            
                # This takes a few minutes. I've saved the output to read in.    
                       for(j in 1920:2020){   
                          tem_sub <- subset(tem_limit, tem_limit$year == j)
                          
                          tem_sub <- left_join(sd4, tem_sub, "stn_id")
                          tem_sub <- subset(tem_sub, is.na(tem_sub$value) == FALSE)
                          tem_sub <- st_drop_geometry(tem_sub)   # goes faster
                          ts2 <- tem_sub %>%
                            group_by(doy, year, id) %>%
                            dplyr::summarise(value = mean(value, na.rm = TRUE), n_stn = n())
          
                      
                        # Note that these exact thresholds are used based on distribution of species
                        # some of the object names below still use older thresholds that were arbitrarily
                        # chosen, but those apply on to the objec names, not the processing.
                          snap_threshs <- c(13.9, 15.5, 17.4, 32.1, 33.6, 34.8)
                          
                          
                          # ts2$cs_1day <- NA
                          # ts2$cs_2day <- NA
                          # ts2$cs_3day <- NA
                          
                          snap_days <- data.frame(id = unique(ts2$id), year = j)
                        
                          for(k in 1:nrow(snap_days)){
                            sub <- as.data.frame(subset(ts2, ts2$id == snap_days$id[k]))
                          
                          # Threshold 1 (cold)
                            snap_threshold <- snap_threshs[1]
                            if(nrow(sub) > 3){
                                sub$cs_1day <- NA
                                sub$cs_2day <- NA
                                sub$cs_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$cs_1day[i] <- FALSE
                                  sub$cs_1day[i] <- sub$value[i]/10 < snap_threshold
                                  sub$cs_2day[i] <- FALSE
                                  if(sub$cs_1day[i] == TRUE){sub$cs_2day[i] <- sub$value[i-1]/10 < snap_threshold}
                                  sub$cs_3day[i] <- FALSE
                                  if(sub$cs_2day[i] == TRUE){sub$cs_3day[i] <- sub$value[i-2]/10 < snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) == 0){snap_days$last_1d13.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) > 0){snap_days$last_1d13.5[k] <- max(subset(sub$doy, sub$cs_1day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) == 0){snap_days$last_2d13.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) > 0){snap_days$last_2d13.5[k] <- max(subset(sub$doy, sub$cs_2day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) == 0){snap_days$last_3d13.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) > 0){snap_days$last_3d13.5[k] <- max(subset(sub$doy, sub$cs_3day == TRUE))}
                            }
                           # Threshold 2 (cold)
                            snap_threshold <- snap_threshs[2]
                            if(nrow(sub) > 3){
                                sub$cs_1day <- NA
                                sub$cs_2day <- NA
                                sub$cs_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$cs_1day[i] <- FALSE
                                  sub$cs_1day[i] <- sub$value[i]/10 < snap_threshold
                                  sub$cs_2day[i] <- FALSE
                                  if(sub$cs_1day[i] == TRUE){sub$cs_2day[i] <- sub$value[i-1]/10 < snap_threshold}
                                  sub$cs_3day[i] <- FALSE
                                  if(sub$cs_2day[i] == TRUE){sub$cs_3day[i] <- sub$value[i-2]/10 < snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) == 0){snap_days$last_1d16[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) > 0){snap_days$last_1d16[k] <- max(subset(sub$doy, sub$cs_1day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) == 0){snap_days$last_2d16[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) > 0){snap_days$last_2d16[k] <- max(subset(sub$doy, sub$cs_2day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) == 0){snap_days$last_3d16[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) > 0){snap_days$last_3d16[k] <- max(subset(sub$doy, sub$cs_3day == TRUE))}
                            } 
                          # Threshold 3 (cold)
                            snap_threshold <- snap_threshs[3]
                            if(nrow(sub) > 3){
                                sub$cs_1day <- NA
                                sub$cs_2day <- NA
                                sub$cs_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$cs_1day[i] <- FALSE
                                  sub$cs_1day[i] <- sub$value[i]/10 < snap_threshold
                                  sub$cs_2day[i] <- FALSE
                                  if(sub$cs_1day[i] == TRUE){sub$cs_2day[i] <- sub$value[i-1]/10 < snap_threshold}
                                  sub$cs_3day[i] <- FALSE
                                  if(sub$cs_2day[i] == TRUE){sub$cs_3day[i] <- sub$value[i-2]/10 < snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) == 0){snap_days$last_1d18.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_1day == TRUE)) > 0){snap_days$last_1d18.5[k] <- max(subset(sub$doy, sub$cs_1day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) == 0){snap_days$last_2d18.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_2day == TRUE)) > 0){snap_days$last_2d18.5[k] <- max(subset(sub$doy, sub$cs_2day == TRUE))}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) == 0){snap_days$last_3d18.5[k] <- NA}
                                 if(nrow(subset(sub, sub$cs_3day == TRUE)) > 0){snap_days$last_3d18.5[k] <- max(subset(sub$doy, sub$cs_3day == TRUE))}
                            }  
                            
                        # Threshold 4 (hot)
                            snap_threshold <- snap_threshs[4]
                            if(nrow(sub) > 3){
                                sub$hw_1day <- NA
                                sub$hw_2day <- NA
                                sub$hw_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$hw_1day[i] <- FALSE
                                  sub$hw_1day[i] <- sub$value[i]/10 > snap_threshold
                                  sub$hw_2day[i] <- FALSE
                                  if(sub$hw_1day[i] == TRUE){sub$hw_2day[i] <- sub$value[i-1]/10 > snap_threshold}
                                  sub$hw_3day[i] <- FALSE
                                  if(sub$hw_2day[i] == TRUE){sub$hw_3day[i] <- sub$value[i-2]/10 > snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) == 0){snap_days$first_1d26[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) > 0){snap_days$first_1d26[k] <- min(subset(sub$doy, sub$hw_1day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) == 0){snap_days$first_2d26[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) > 0){snap_days$first_2d26[k] <- min(subset(sub$doy, sub$hw_2day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) == 0){snap_days$first_3d26[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) > 0){snap_days$first_3d26[k] <- min(subset(sub$doy, sub$hw_3day == TRUE))}
                            }
                            
                        # Threshold 5 (hot)
                            snap_threshold <- snap_threshs[5]
                            if(nrow(sub) > 3){
                                sub$hw_1day <- NA
                                sub$hw_2day <- NA
                                sub$hw_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$hw_1day[i] <- FALSE
                                  sub$hw_1day[i] <- sub$value[i]/10 > snap_threshold
                                  sub$hw_2day[i] <- FALSE
                                  if(sub$hw_1day[i] == TRUE){sub$hw_2day[i] <- sub$value[i-1]/10 > snap_threshold}
                                  sub$hw_3day[i] <- FALSE
                                  if(sub$hw_2day[i] == TRUE){sub$hw_3day[i] <- sub$value[i-2]/10 > snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) == 0){snap_days$first_1d31[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) > 0){snap_days$first_1d31[k] <- min(subset(sub$doy, sub$hw_1day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) == 0){snap_days$first_2d31[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) > 0){snap_days$first_2d31[k] <- min(subset(sub$doy, sub$hw_2day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) == 0){snap_days$first_3d31[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) > 0){snap_days$first_3d31[k] <- min(subset(sub$doy, sub$hw_3day == TRUE))}
                            }
                            
                        # Threshold 6 (hot)
                            snap_threshold <- snap_threshs[6]
                            if(nrow(sub) > 3){
                                sub$hw_1day <- NA
                                sub$hw_2day <- NA
                                sub$hw_3day <- NA
                                for(i in 3:nrow(sub)){
                                  sub$hw_1day[i] <- FALSE
                                  sub$hw_1day[i] <- sub$value[i]/10 > snap_threshold
                                  sub$hw_2day[i] <- FALSE
                                  if(sub$hw_1day[i] == TRUE){sub$hw_2day[i] <- sub$value[i-1]/10 > snap_threshold}
                                  sub$hw_3day[i] <- FALSE
                                  if(sub$hw_2day[i] == TRUE){sub$hw_3day[i] <- sub$value[i-2]/10 > snap_threshold}
                                }
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) == 0){snap_days$first_1d36[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_1day == TRUE)) > 0){snap_days$first_1d36[k] <- min(subset(sub$doy, sub$hw_1day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) == 0){snap_days$first_2d36[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_2day == TRUE)) > 0){snap_days$first_2d36[k] <- min(subset(sub$doy, sub$hw_2day == TRUE))}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) == 0){snap_days$first_3d36[k] <- NA}
                                 if(nrow(subset(sub, sub$hw_3day == TRUE)) > 0){snap_days$first_3d36[k] <- min(subset(sub$doy, sub$hw_3day == TRUE))}
                            }    
                            
                          }
                          
                          snaps_temp <- left_join(grid2, snap_days, "id")
                          snaps_temp <- subset(snaps_temp, is.na(snaps_temp$year) == FALSE)
                          if(j == 1920){snaps <- snaps_temp}
                          if(j > 1920){snaps <- rbind(snaps, snaps_temp)}
                          print(j)
                       }
                       
                       # Count number of years of records for each grid and save only grids with >50 years of data   
                           count_years <- data.frame(id = unique(snaps$id), count_years = 0)   
                           for(i in 1:nrow(count_years)){
                             match_id <- count_years$id[i]
                             count_years$count_years[i] <- nrow(subset(snaps, snaps$id == match_id))
                           }
                           snaps <- left_join(snaps, count_years, "id")
                           snaps <- subset(snaps, snaps$count_years > 50)
                     
                     
                           
              # for grids that have NA values for a snap, substitute in the minimum (cold) or maximum (heat) value from that grid
                    snaps$cold_1d_18.5 <- "Yes"
                    snaps$cold_2d_18.5 <- "Yes"
                    snaps$cold_3d_18.5 <- "Yes"
                    snaps$cold_1d_16 <- "Yes"
                    snaps$cold_2d_16 <- "Yes"
                    snaps$cold_3d_16 <- "Yes"
                    snaps$cold_1d_13.5 <- "Yes"
                    snaps$cold_2d_13.5 <- "Yes"
                    snaps$cold_3d_13.5 <- "Yes"
                    snaps$heat_1d_26 <- "Yes"
                    snaps$heat_2d_26 <- "Yes"
                    snaps$heat_3d_26 <- "Yes"
                    snaps$heat_1d_31 <- "Yes"
                    snaps$heat_2d_31 <- "Yes"
                    snaps$heat_3d_31 <- "Yes"
                    snaps$heat_1d_36 <- "Yes"
                    snaps$heat_2d_36 <- "Yes"
                    snaps$heat_3d_36 <- "Yes"
                  for(h in 1:nrow(snaps)){
                    if(is.na(snaps$last_1d18.5[h]) == TRUE){
                      snaps$cold_1d_18.5[h] <- "No"
                      snaps$last_1d18.5[h] <- min(na.omit(subset(snaps$last_1d18.5, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_2d18.5[h]) == TRUE){
                      snaps$cold_2d_18.5[h] <- "No"
                      snaps$last_2d18.5[h] <- min(na.omit(subset(snaps$last_2d18.5, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_3d18.5[h]) == TRUE){
                      snaps$cold_3d_18.5[h] <- "No"
                      snaps$last_3d18.5[h] <- min(na.omit(subset(snaps$last_3d18.5, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_1d16[h]) == TRUE){
                      snaps$cold_1d_16[h] <- "No"
                      snaps$last_1d16[h] <- min(na.omit(subset(snaps$last_1d16, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_2d16[h]) == TRUE){
                      snaps$cold_2d_16[h] <- "No"
                      snaps$last_2d16[h] <- min(na.omit(subset(snaps$last_2d16, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_3d16[h]) == TRUE){
                      snaps$cold_3d_16[h] <- "No"
                      snaps$last_3d16[h] <- min(na.omit(subset(snaps$last_3d16, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_1d13.5[h]) == TRUE){
                      snaps$cold_1d_13.5[h] <- "No"
                      snaps$last_1d13.5[h] <- min(na.omit(subset(snaps$last_1d13.5, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_2d13.5[h]) == TRUE){
                      snaps$cold_2d_13.5[h] <- "No"
                      snaps$last_2d13.5[h] <- min(na.omit(subset(snaps$last_2d13.5, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$last_3d13.5[h]) == TRUE){
                      snaps$cold_3d_13.5[h] <- "No"
                      snaps$last_3d13.5[h] <- min(na.omit(subset(snaps$last_3d13.5, snaps$id == snaps$id[h])))}
                    
                    if(is.na(snaps$first_1d26[h]) == TRUE){
                      snaps$heat_1d_26[h] <- "No"
                      snaps$first_1d26[h] <- max(na.omit(subset(snaps$first_1d26, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_2d26[h]) == TRUE){
                      snaps$heat_2d_26[h] <- "No"
                      snaps$first_2d26[h] <- max(na.omit(subset(snaps$first_2d26, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_3d26[h]) == TRUE){
                      snaps$heat_3d_26[h] <- "No"
                      snaps$first_3d26[h] <- max(na.omit(subset(snaps$first_3d26, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_1d31[h]) == TRUE){
                      snaps$heat_1d_31[h] <- "No"
                      snaps$first_1d31[h] <- max(na.omit(subset(snaps$first_1d31, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_2d31[h]) == TRUE){
                      snaps$heat_2d_31[h] <- "No"
                      snaps$first_2d31[h] <- max(na.omit(subset(snaps$first_2d31, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_3d31[h]) == TRUE){
                      snaps$heat_3d_31[h] <- "No"
                      snaps$first_3d31[h] <- max(na.omit(subset(snaps$first_3d31, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_1d36[h]) == TRUE){
                      snaps$heat_1d_36[h] <- "No"
                      snaps$first_1d36[h] <- max(na.omit(subset(snaps$first_1d36, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_2d36[h]) == TRUE){
                      snaps$heat_2d_36[h] <- "No"
                      snaps$first_2d36[h] <- max(na.omit(subset(snaps$first_2d36, snaps$id == snaps$id[h])))}
                    if(is.na(snaps$first_3d36[h]) == TRUE){
                      snaps$heat_3d_36[h] <- "No"
                      snaps$first_3d36[h] <- max(na.omit(subset(snaps$first_3d36, snaps$id == snaps$id[h])))}
                  }
                           
                  for(h in 1:nrow(snaps)){
                    if(is.finite(snaps$last_1d18.5[h]) == FALSE){snaps$last_1d18.5[h] <- NA}
                    if(is.finite(snaps$last_2d18.5[h]) == FALSE){snaps$last_2d18.5[h] <- NA}
                    if(is.finite(snaps$last_3d18.5[h]) == FALSE){snaps$last_3d18.5[h] <- NA}
                    if(is.finite(snaps$last_1d16[h]) == FALSE){snaps$last_1d16[h] <- NA}
                    if(is.finite(snaps$last_2d16[h]) == FALSE){snaps$last_2d16[h] <- NA}
                    if(is.finite(snaps$last_3d16[h]) == FALSE){snaps$last_3d16[h] <- NA}
                    if(is.finite(snaps$last_1d13.5[h]) == FALSE){snaps$last_1d13.5[h] <- NA}
                    if(is.finite(snaps$last_2d13.5[h]) == FALSE){snaps$last_2d13.5[h] <- NA}
                    if(is.finite(snaps$last_3d13.5[h]) == FALSE){snaps$last_3d13.5[h] <- NA}
                    
                    if(is.finite(snaps$first_1d26[h]) == FALSE){snaps$first_1d26[h] <- NA}
                    if(is.finite(snaps$first_2d26[h]) == FALSE){snaps$first_2d26[h] <- NA}
                    if(is.finite(snaps$first_3d26[h]) == FALSE){snaps$first_3d26[h] <- NA}
                    if(is.finite(snaps$first_1d31[h]) == FALSE){snaps$first_1d31[h] <- NA}
                    if(is.finite(snaps$first_2d31[h]) == FALSE){snaps$first_2d31[h] <- NA}
                    if(is.finite(snaps$first_3d31[h]) == FALSE){snaps$first_3d31[h] <- NA}
                    if(is.finite(snaps$first_1d36[h]) == FALSE){snaps$first_1d36[h] <- NA}
                    if(is.finite(snaps$first_2d36[h]) == FALSE){snaps$first_2d36[h] <- NA}
                    if(is.finite(snaps$first_3d36[h]) == FALSE){snaps$first_3d36[h] <- NA}
                  }         
                       
                           #saveRDS(snaps, here::here("6_saved_data_objects/cold_snaps.rds"))    
               # Load in the saved object from the loop above      
                    #snaps <- readRDS(here::here("6_saved_data_objects/cold_snaps.rds"))             
                          
          }

    
        
```

```{r get-anomaly, echo = FALSE, message = FALSE, warning = FALSE}
if(run_anomaly_process == "yes"){
  # Temperature anomaly data ----
    #  I'm using data from a Berkeley project:     http://berkeleyearth.org/archive/data/
         # and following a bit of this tutorial: https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/time-series-analysis/Data-sets-used/Earth-surface-temperature-anomalies/index.html
         # and this tutorial: https://rpubs.com/boyerag/297592
         
      # The gridded data comes in ncdf format and needs to be converted. This was downloaded manually from Berkeley
         nc_data <- nc_open(here::here("6_saved_data_objects/Complete_TAVG_LatLong1.nc"))
         {
           sink(here::here("6_saved_data_objects/sink_anomaly.txt"))
           print(nc_data)
           sink()
         }
      
      # This is just extracting the parts from the three dimensional grid  
          long <- ncvar_get(nc_data, "longitude")
          lat <- ncvar_get(nc_data, "latitude")
          time <- ncvar_get(nc_data, "time")
          time2 <- as.vector(time)
          time2 <- round(time2, 3)
          anom.array <- ncvar_get(nc_data, "temperature")
          fillvalue <- ncatt_get(nc_data, "temperature", "_FillValue")
          nc_close(nc_data)
      
      # Looping through each year and turning this into a long format data object 
          for(i in 1920:2020){
            time_slice_apr <- anom.array[ , , match(i + 0.292, time2)]
            rownames(time_slice_apr) <- long
            colnames(time_slice_apr) <- lat
            ts_ap <- reshape2::melt(time_slice_apr)
            ts_ap$year <- rep(i, nrow(ts_ap))
            if(i == 1920){ts_a <- ts_ap}
            if(i > 1920){ts_a <- rbind(ts_a, ts_ap)}
          
          
            time_slice_may <- anom.array[ , , match(i + 0.375, time2)]
            rownames(time_slice_may) <- long
            colnames(time_slice_may) <- lat
            ts_mp <- reshape2::melt(time_slice_may)
            ts_mp$year <- rep(i, nrow(ts_mp))
            if(i == 1920){ts_m <- ts_mp}
            if(i > 1920){ts_m <- rbind(ts_m, ts_mp)}
          
            time_slice_jun <- anom.array[ , , match(i + 0.458, time2)]
            rownames(time_slice_jun) <- long
            colnames(time_slice_jun) <- lat
            ts_jp <- reshape2::melt(time_slice_jun)
            ts_jp$year <- rep(i, nrow(ts_jp))
            if(i == 1920){ts_j <- ts_jp}
            if(i > 1920){ts_j <- rbind(ts_j, ts_jp)}
            
            print(i)
          }
      
      # Getting average anomaly for April/May/June. Could add other months
          ts_a_mu <- ts_a %>%
            filter(year > 1994 ) %>%
            group_by(Var1, Var2) %>%
            dplyr::summarise(value = mean(value))
          
          ts_m_mu <- ts_m %>%
            filter(year > 1994 ) %>%
            group_by(Var1, Var2) %>%
            dplyr::summarise(value = mean(value))
          
          ts_j_mu <- ts_j %>%
            filter(year > 1994 ) %>%
            group_by(Var1, Var2) %>%
            dplyr::summarise(value = mean(value))
      
      # Combining April/May/June into one dataframe
          ts_a_mu$month <- "April"
          ts_m_mu$month <- "May"
          ts_j_mu$month <- "June"
          ts_c_mu <- rbind(ts_a_mu, ts_m_mu, ts_j_mu)
      
          ts_c_mu$month <- factor(ts_c_mu$month, levels = c("April", "May", "June"))
      
      # Combined plot of the three months with average anomaly from 1996-2020
          p_comb <- ggplot(data = ts_c_mu) + 
            geom_raster(data = ts_c_mu, mapping = aes(x = Var1, y = Var2, fill = value), na.rm = TRUE) + 
            scale_fill_gradient2(low = "#542788", high = "#b35806", mid = "#f7f7f7", midpoint = 0,
                                 na.value = rgb(211, 211, 211, max = 255, alpha = 0, names = "clear"),
                                 limits = c(-1, 3.5)) +
            xlim(c(-135, -62)) + ylim(c(20, 60)) +
            theme_gray() + ylab("Latitude") + xlab("Longitude") +
            theme(legend.position = "top") +
            ggtitle(label = "Average 1996 - 2020") +
            facet_wrap(~month)
      
            ggsave(here::here("3_r_scripts", "avg_anomaly.png"), p_comb,
                   device = "png", width = 10.5, height = 4)

    # Combined object with all three months and all years separate
          ts_a$month <- "April"
          ts_m$month <- "May"
          ts_j$month <- "June"
          ts_c <- rbind(ts_a, ts_m, ts_j)
    
        ts_c$month <- factor(ts_c$month, levels = c("April", "May", "June"))
    
    # Make animated gif that scrolls through each year from 1996-2020 and shows anomaly        
      #  anim <- ggplot(data = ts_c) + 
      #    geom_raster(data = ts_c, mapping = aes(x = Var1, y = Var2, fill = value), na.rm = TRUE) + 
      #    scale_fill_gradient2(low = "#542788", high = "#b35806", mid = "#f7f7f7", midpoint = 0,
      #                         na.value = rgb(211, 211, 211, max = 255, alpha = 0, names = "clear"),
      #                         limits = c(-7, 7)) +
      #    xlim(c(-135, -62)) + ylim(c(20, 60)) +
      #    theme_gray() + ylab("Latitude") + xlab("Longitude") +
      #    theme(legend.position = "top") +
      #    #annotate("text", x = -Inf, y =  -Inf, label = '{closet_state}', hjust = -0.1, vjust = -1, size = 1.5) +
       #   facet_wrap(~month) +
      #    transition_states(as.factor(year), transition_length = 1, state_length = 2) +
      #    ggtitle(label = '{closest_state}')
        
      #  anim_save(here::here("3_r_scripts", "spring_anomaly_anim.gif"), animate(anim, duration = 12, width = 1000, height = 380, renderer = gifski_renderer()))
    
            
                        
# Anomaly to hex grid by year ----

        
    for(u in 1920:max(na.omit(ts_c$year))){
      # Make grid into lat long to extract
        grid_ex <- st_transform(grid2, st_crs(namer_o))
      
      # Subset to one year
        ts_sub <- subset(ts_c, ts_c$year == u)
      
      # April
        ts_suba <- subset(ts_sub, ts_sub$month == "April")
        coordinates(ts_suba) <- ~ Var1 + Var2
        gridded(ts_suba) <- TRUE
        ts_suba_ras <- raster(ts_suba)
        crs(ts_suba_ras) <- crs(namer_o)
        
        grid_an <- raster::extract(x = ts_suba_ras, y = grid_ex)
        grid_ex$apr_anom <- unlist(lapply(grid_an, function(x) if(!is.null(x)) mean(x, na.rm = TRUE) else NA))

      # May
        ts_subm <- subset(ts_sub, ts_sub$month == "May")
        coordinates(ts_subm) <- ~ Var1 + Var2
        gridded(ts_subm) <- TRUE
        ts_subm_ras <- raster(ts_subm)
        crs(ts_subm_ras) <- crs(namer_o)
        
        grid_an <- raster::extract(x = ts_subm_ras, y = grid_ex)
        grid_ex$may_anom <- unlist(lapply(grid_an, function(x) if(!is.null(x)) mean(x, na.rm = TRUE) else NA))        
             
      # June
        ts_subj <- subset(ts_sub, ts_sub$month == "June")
        coordinates(ts_subj) <- ~ Var1 + Var2
        gridded(ts_subj) <- TRUE
        ts_subj_ras <- raster(ts_subj)
        crs(ts_subj_ras) <- crs(namer_o)
        
        grid_an <- raster::extract(x = ts_subj_ras, y = grid_ex)
        grid_ex$jun_anom <- unlist(lapply(grid_an, function(x) if(!is.null(x)) mean(x, na.rm = TRUE) else NA))     
        
      # export
        grid_ex$year <- u
        if(u == unique(ts_c$year)[1]){grid_save <- grid_ex}
        if(u > unique(ts_c$year)[1]){grid_save <- rbind(grid_save, grid_ex)}
        
        print(u)
        
    }    
        
    #snaps_av$centroid <- st_centroid(snaps_av$geometry)
    #      st_geometry(snaps_av) <- "centroid"
    #      snaps_av2 <- st_join(grid2, snaps_av)    
        
  # Add centroid locations to hex grids      
        add_cent <- grid2
        add_cent$centroid <- st_centroid(add_cent$geometry)
        st_geometry(add_cent) <- "centroid"
        add_cent$c_long <- st_coordinates(add_cent)[, 1]
        add_cent$c_lat <- st_coordinates(add_cent)[, 2]
        add_cent <- st_drop_geometry(add_cent)
        add_cent <- add_cent[, c("id", "c_long", "c_lat")]
        
        grid2 <- left_join(grid2, add_cent, "id")
        
  # join snaps and anomaly
        anom_only <- st_drop_geometry(grid_save)
        anom_only$y_id <- paste(anom_only$id, anom_only$year, sep = "_")
        snap_only <- st_drop_geometry(snaps)
        snap_only$y_id <- paste(snap_only$id, snap_only$year, sep = "_")
        
        anom_snap <- plyr::join(anom_only, snap_only, type = "full", by = "y_id")
        anom_snap2 <- left_join(grid2, anom_snap, by = "id", match = "all")
        
        colnames(anom_snap2)[2:3] <- c("n", "lay")
        
        anom_snap2$spring_anomaly <- (anom_snap2$apr_anom + anom_snap2$may_anom + anom_snap2$jun_anom) / 3
        
    # Make baseline 1951-1980 cold snap occurrence
        base_anom <- subset(anom_snap2, anom_snap2$year > 1950 & anom_snap2$year < 1981)
        base_anom <- st_drop_geometry(base_anom)
        
        # base_anom2 <- base_anom %>%
        #   group_by(id) %>%
        #   summarise(mu_1d18.5 = mean(na.omit(subset(last_1d18.5, cold_1d_18.5 == "Yes"))),
        #             mu_2d18.5 = mean(na.omit(subset(last_2d18.5, cold_2d_18.5 == "Yes"))),
        #             mu_3d18.5 = mean(na.omit(subset(last_3d18.5, cold_3d_18.5 == "Yes"))),
        #             mu_1d16 = mean(na.omit(subset(last_1d16, cold_1d_16 == "Yes"))),
        #             mu_2d16 = mean(na.omit(subset(last_2d16, cold_2d_16 == "Yes"))),
        #             mu_3d16 = mean(na.omit(subset(last_3d16, cold_3d_16 == "Yes"))),
        #             mu_1d13.5 = mean(na.omit(subset(last_1d13.5, cold_1d_13.5 == "Yes"))),
        #             mu_2d13.5 = mean(na.omit(subset(last_2d13.5, cold_2d_13.5 == "Yes"))),
        #             mu_3d13.5 = mean(na.omit(subset(last_3d13.5, cold_3d_13.5 == "Yes"))),
        #             mu_1d26 = mean(na.omit(subset(first_1d26, heat_1d_26 == "Yes"))),
        #             mu_2d26 = mean(na.omit(subset(first_2d26, heat_2d_26 == "Yes"))),
        #             mu_3d26 = mean(na.omit(subset(first_3d26, heat_3d_26 == "Yes"))),
        #             mu_1d31 = mean(na.omit(subset(first_1d31, heat_1d_31 == "Yes"))),
        #             mu_2d31 = mean(na.omit(subset(first_2d31, heat_2d_31 == "Yes"))),
        #             mu_3d31 = mean(na.omit(subset(first_3d31, heat_3d_31 == "Yes"))),
        #             mu_1d36 = mean(na.omit(subset(first_1d36, heat_1d_36 == "Yes"))),
        #             mu_2d36 = mean(na.omit(subset(first_2d36, heat_2d_36 == "Yes"))),
        #             mu_3d36 = mean(na.omit(subset(first_3d36, heat_3d_36 == "Yes"))))
        
      #including years with subbed in anomalies  
        base_anom2 <- base_anom %>%
          dplyr::group_by(id) %>%
          dplyr::summarise(mu_1d18.5 = mean(na.omit(last_1d18.5)),
                    mu_2d18.5 = mean(na.omit(last_2d18.5)),
                    mu_3d18.5 = mean(na.omit(last_3d18.5)),
                    mu_1d16 = mean(na.omit(last_1d16)),
                    mu_2d16 = mean(na.omit(last_2d16)),
                    mu_3d16 = mean(na.omit(last_3d16)),
                    mu_1d13.5 = mean(na.omit(last_1d13.5)),
                    mu_2d13.5 = mean(na.omit(last_2d13.5)),
                    mu_3d13.5 = mean(na.omit(last_3d13.5)),
                    mu_1d26 = mean(na.omit(first_1d26)),
                    mu_2d26 = mean(na.omit(first_2d26)),
                    mu_3d26 = mean(na.omit(first_3d26)),
                    mu_1d31 = mean(na.omit(first_1d31)),
                    mu_2d31 = mean(na.omit(first_2d31)),
                    mu_3d31 = mean(na.omit(first_3d31)),
                    mu_1d36 = mean(na.omit(first_1d36)),
                    mu_2d36 = mean(na.omit(first_2d36)),
                    mu_3d36 = mean(na.omit(first_3d36)))
        
        anom_snap2 <- left_join(anom_snap2, base_anom2, "id")
        
      # Calculate cold snap anomaly dates by year and grid
        anom_snap2$a_1d18 <- anom_snap2$last_1d18.5 - anom_snap2$mu_1d18.5
        anom_snap2$a_2d18 <- anom_snap2$last_2d18.5 - anom_snap2$mu_2d18.5
        anom_snap2$a_3d18 <- anom_snap2$last_3d18.5 - anom_snap2$mu_3d18.5
        
        anom_snap2$a_1d16 <- anom_snap2$last_1d16 - anom_snap2$mu_1d16
        anom_snap2$a_2d16 <- anom_snap2$last_2d16 - anom_snap2$mu_2d16
        anom_snap2$a_3d16 <- anom_snap2$last_3d16 - anom_snap2$mu_3d16 
        
        anom_snap2$a_1d13 <- anom_snap2$last_1d13.5 - anom_snap2$mu_1d13.5
        anom_snap2$a_2d13 <- anom_snap2$last_2d13.5 - anom_snap2$mu_2d13.5
        anom_snap2$a_3d13 <- anom_snap2$last_3d13.5 - anom_snap2$mu_3d13.5
        
      # Calculate heat wave anomaly dates by year and grid  
        anom_snap2$a_1d26 <- anom_snap2$first_1d26 - anom_snap2$mu_1d26
        anom_snap2$a_2d26 <- anom_snap2$first_2d26 - anom_snap2$mu_2d26
        anom_snap2$a_3d26 <- anom_snap2$first_3d26 - anom_snap2$mu_3d26
        
        anom_snap2$a_1d31 <- anom_snap2$first_1d31 - anom_snap2$mu_1d31
        anom_snap2$a_2d31 <- anom_snap2$first_2d31 - anom_snap2$mu_2d31
        anom_snap2$a_3d31 <- anom_snap2$first_3d31 - anom_snap2$mu_3d31 
        
        anom_snap2$a_1d36 <- anom_snap2$first_1d36 - anom_snap2$mu_1d36
        anom_snap2$a_2d36 <- anom_snap2$first_2d36 - anom_snap2$mu_2d36
        anom_snap2$a_3d36 <- anom_snap2$first_3d36 - anom_snap2$mu_3d36
        
      # drop some columns
        #anom_snap2$c_long <- anom_snap2$c_long.x
        #anom_snap2$c_lat <- anom_snap2$c_lat.x
        anom_snap2 <- anom_snap2[, c("id", "year", "y_id", "n", "lay", "c_long", "c_lat", 
                                     "spring_anomaly", "apr_anom", "may_anom", "jun_anom", 
                                     "last_1d18.5", "last_2d18.5", "last_3d18.5", "last_1d16", "last_2d16", "last_3d16", "last_1d13.5", "last_2d13.5", "last_3d13.5",
                                     "mu_1d18.5", "mu_2d18.5", "mu_3d18.5", "mu_1d16", "mu_2d16", "mu_3d16", "mu_1d13.5", "mu_2d13.5", "mu_3d13.5",
                                     "a_1d18", "a_2d18", "a_3d18", "a_1d16", "a_2d16", "a_3d16", "a_1d13", "a_2d13", "a_3d13",
                                     "first_1d26", "first_2d26", "first_3d26", "first_1d31", "first_2d31", "first_3d31", "first_1d36", "first_2d36", "first_3d36",
                                     "mu_1d26", "mu_2d26", "mu_3d26", "mu_1d31", "mu_2d31", "mu_3d31", "mu_1d36", "mu_2d36", "mu_3d36",
                                     "a_1d26", "a_2d26", "a_3d26", "a_1d31", "a_2d31", "a_3d31", "a_1d36", "a_2d36", "a_3d36",
                                     "cold_1d_18.5", "cold_2d_18.5", "cold_3d_18.5", "cold_1d_16", "cold_2d_16", "cold_3d_16",
                                     "cold_1d_13.5", "cold_2d_13.5", "cold_3d_13.5", "heat_1d_26", "heat_2d_26", "heat_3d_26",
                                     "heat_1d_31", "heat_2d_31", "heat_3d_31", "heat_1d_36", "heat_2d_36", "heat_3d_36")]
        
        
        # save object with anomaly and snap data
          saveRDS(anom_snap2, here::here("6_saved_data_objects/cold_snaps.rds"))
      
}
        snaps <- readRDS(here::here("6_saved_data_objects/cold_snaps.rds"))

```

```{r nest-temperature, message = FALSE, warning = FALSE, echo = FALSE}

# # Read in weather
  # tem <- readRDS(here::here("6_saved_data_objects/t_MAX.rds"))
  # can_tem <- readRDS(here::here("6_saved_data_objects/canada_max.rds"))
  # tem <- rbind(tem, can_tem)
  # tem95 <- subset(tem, tem$year > 1994 & tem$doy > 50 & tem$doy < 250)
# 
# # make list of stations that are in temperature data
#   stn95 <- tem95[!duplicated(tem95$station_id), ]
#   colnames(stn95)[1] <- "stn_id"
#   stn95 <- left_join(sd4, stn95, "stn_id")
#   stn95 <- subset(stn95, is.na(stn95$reading) == FALSE)
# 
# # Add elevation to station list
#   stn_el <- stn95
#   #stn_el <- st_transform(stn_el, st_crs(namer_o))
#   stn_el$elevation <- extract(dem, stn_el)
#   stn_el <- subset(stn_el, is.na(stn_el$elevation) == FALSE)
#   #stn_el <- st_transform(stn_el, st_crs(proj_code))
#   saveRDS(stn_el, here::here("6_saved_data_objects/stations_with_elev.rds"))
#   stn_el <- readRDS(here::here("6_saved_data_objects/stations_with_elev.rds"))
# 
# # set distance and elevation comparisons
#   search_dist <- 50000 #50 kilometers
#   elev_limit <- 300 #300 meters
# 
# # Loop through and find closest station
#   begin <- Sys.time()
#   for(i in 1:nrow(dsfo)){
#     look <- dsfo[i, ]
#     dists <- as.vector(st_distance(look, stn_el))
#     #pos_stns <- stn_el[dists < search_dist, ]
#     matcher <- stn_el[which.min(dists), ]
#     dsfo$stn_id[i] <- matcher$stn_id
#     dsfo$stn_elev[i] <- matcher$elevation
#     dsfo$stn_dist[i] <- min(dists)
#     stn_diff <- abs(dsfo$stn_elev[i] - matcher$elevation)
#     #add distance to station
#     dsfo$match_type[i] <- "normal"
#     if(stn_dist > elev_limit){
#       dists <- as.vector(st_distance(look, stn_el))
#       pos_stns <- stn_el[dists < search_dist, ]
#       pos_stns$el_dif <- abs(rep(look$elevation, nrow(pos_stns)) - pos_stns$elevation)
#       matcher2 <- stn_el[which.min(pos_stns$elevation), ]
#       dsfo$id[i] <- matcher2$id
#       dsfo$stn_elev[i] <- matcher2$elevation
#       dsfo$match_type[i] <- "sub_elev"
#       dsfo$stn_dist[i] <- as.vector(st_distance(look, matcher2))
#     }
#     print(i)
#   }
#   end <- Sys.time()
#   end - begin
# 
#   dsfo$elev_dif <- dsfo$elevation - dsfo$stn_elev
#   
#   saveRDS(dsfo, here::here("6_saved_data_objects/records_with_stns.rds"))
  
  dsfo <- readRDS(here::here("6_saved_data_objects/records_with_stns.rds"))

# for(i in 1:nrow(dsfo)){
#   if(dsfo$stn_diff[i] > elev_limit){
#       look <- dsfo[i, ]
#       dists <- as.vector(st_distance(look, stn_el))
#       pos_stns <- stn_el[dists < search_dist, ]
#       if(nrow(pos_stns) > 0){
#         pos_stns$el_dif <- abs(rep(look$elevation, nrow(pos_stns)) - pos_stns$elevation)
#         matcher2 <- stn_el[which.min(pos_stns$elevation), ]
#         dsfo$id[i] <- matcher2$id
#         dsfo$stn_elev[i] <- matcher2$elevation
#         dsfo$match_type[i] <- "sub_elev"
#         dsfo$stn_dist[i] <- as.vector(st_distance(look, matcher2))
#       }
#       print(i)
#     }
# }
#     

```

```{r snaps-plot, echo = FALSE, message = FALSE, warning = FALSE}
# Convert to a long term average date of last cold snap for each grid
          snaps95 <- subset(snaps, snaps$year > 1994)
          snaps_av <- snaps95 %>%
            dplyr::group_by(id) %>%
            dplyr::summarise(mu_1d = mean(subset(last_1d18.5, cold_1d_18.5 == "Yes"), na.rm = TRUE), 
                             mu_2d = mean(subset(last_2d18.5, cold_2d_18.5 == "Yes"), na.rm = TRUE), 
                             mu_3d = mean(subset(last_3d18.5, cold_3d_18.5 == "Yes"), na.rm = TRUE),
                             anom_3d = mean(a_3d18, na.rm = TRUE))
          # the mu columns here are not using imputed rows but they aren't plotted
            
            # p3d <- ggplot(data = snaps_av) + geom_sf(data = namer, fill = "gray75") +
            #   theme_bw() +
            #   #xlim(c(-130, -66)) + ylim(c(22, 58)) +
            #   scale_fill_viridis(alpha = 0.8, option = "inferno", direction = -1) +
            #   xlab("Longitude") + ylab("Latitude") +
            #   theme(legend.position = "top") +
            #   guides(fill = guide_colourbar(title = "Day of \n year")) +
            #   geom_sf(data = snaps_av, mapping = aes(fill = mu_3d), alpha = 0.7) +
            #   coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
            #   theme(axis.title = element_text(size = 16)) +
            #   theme(legend.background = element_rect(fill = "transparent"))
            
            p_anom_avg <- ggplot(data = snaps_av) + geom_sf(data = namer, fill = "gray75") + 
              theme_bw() +
              #scale_fill_viridis(alpha = 0.8, option = "inferno", direction = -1) + 
              scale_fill_gradient2(high = "#7B3294", low = "#008837", mid = "#F7F7F7", midpoint = 0,
                   na.value = rgb(211, 211, 211, max = 255, alpha = 0.4, names = "clear"),
                   limits = c(-20, 12)) +
              xlab("Longitude") + ylab("Latitude") +
              theme(legend.position = "top") + 
              guides(fill = guide_colourbar(title = "Cold-snap \n anomaly")) +
              geom_sf(data = snaps_av, mapping = aes(fill = anom_3d), alpha = 0.8) + 
              coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
              theme(axis.title = element_text(size = 12)) +
              theme(legend.background = element_rect(fill = "transparent"))
              
            
            #p3d2 <- p3d + geom_sf(data = grid2, fill = "blue") +
            #  geom_sf_text(data = grid2, aes(label = id), color = "white")
            
            #p3d3 <- p3d + geom_sf_text(data = snaps_av, aes(label = id), color = "white")
            
```

```{r snap-trend, echo = FALSE, warning = FALSE, message = FALSE, fig.align = "center", fig.width = 7.5, fig.height = 4.8, fig.cap = "Average date of the latest three day period in which daytime temperatures did not rise above 18.5 degrees from 1995-2020. All cells with breeding records are included; gray cells did not have sufficient historical temperature data to calculate cold snaps. Small panels show the historical trend in the timing of cold snaps for cells in four equal latitude bands as an anomaly from the average cold snap date between 1951-1980; latitude ranges are listed in the header of each panel. Lines show smoothed fits and standard errors from generalized additive models for illustration. The solid dashed line indicates the baseline average cold snap date. Points below the line show years where the last cold snap occurs earlier than the baseline and points above show years where the last cold snap occurs later than the baseline."}
# Builds on previous chunk looking at historic change in cold snap timing
    # Group hexagons by latitude of centroid
        snaps2 <- snaps
        snaps2$centroid <- st_centroid(snaps$geometry)
        st_geometry(snaps2) <- "centroid"
        snaps2 <- st_transform(snaps2, st_crs(namer_o))
        
        centers <- data.frame(st_coordinates(snaps2))
        snaps2$lat <- centers$Y
        snaps2$long <- centers$X
    # Now convert back to abers
        snaps3 <- st_transform(snaps2, proj_code)
    
        
    # cut into four groups by latitude    
        snaps3$grp <- cut(snaps3$lat, 4)
        snaps3 <- subset(snaps3, is.na(snaps3$lat) == FALSE)
        snaps3$grp <- factor(snaps3$grp, levels = c("(49.9,58.1]", "(41.6,49.9]", "(33.4,41.6]","(25.2,33.4]"))
        sngrp <- data.frame(grp = c("(49.9,58.1]", "(41.6,49.9]", "(33.4,41.6]","(25.2,33.4]"),
                            grp2 = c("(50-58)", "(42-50)", "(33-42)", "(25-33)"))
        snaps3 <- left_join(snaps3, sngrp, "grp")
        snaps3$grp2 <- factor(snaps3$grp2, levels = c("(50-58)", "(42-50)", "(33-42)", "(25-33)"))
        
    # Plot change in historic cold snaps split by latitude
        snap_change <- ggplot(data = snaps3, mapping = aes(x = year, y = a_3d18, fill = grp2, color = grp2)) +
          #scale_fill_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          #scale_color_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          geom_hline(yintercept = 0, linetype = "dashed") +
          geom_smooth(color = "coral3", fill = "coral3") + theme_bw() +
          ylab("3-day cold snap anomaly") +
          xlab("Year") +
          theme(axis.title = element_text(size = 16)) +
          facet_wrap(~ grp2, nrow = 4, strip.position = "top") +
          guides(fill = "none", color = "none") +
          #theme(strip.background = element_blank(), strip.text = element_blank()) +
        theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
          coord_cartesian(ylim = c(-15, 15), xlim = c(1920, 2017))
          
        
        cold_supp <- ggarrange(p_anom_avg, snap_change, nrow = 1, widths = c(2.5, 1))
        saveRDS(cold_supp, here::here("4_output_figures", "cold_supp.rds"))
          
    
```

```{r anomaly-plot, echo = FALSE, message = FALSE, warning = FALSE}
# Convert to a long term average date of last cold snap for each grid
          snaps95 <- subset(snaps, snaps$year > 1994)
          snaps_av <- snaps95 %>%
            dplyr::group_by(id) %>%
            dplyr::summarise(anom = mean(spring_anomaly, na.rm = TRUE))
            
            p_anom <- ggplot(data = snaps_av) + geom_sf(data = namer, fill = "gray75") + 
              theme_bw() +
              #xlim(c(-130, -66)) + ylim(c(22, 58)) + 
              #scale_fill_viridis(alpha = 0.8, option = "inferno", direction = 1) + 
              scale_fill_gradient2(low = "#542788", high = "#b35806", mid = "#f7f7f7", midpoint = 0,
                                 na.value = rgb(211, 211, 211, max = 255, alpha = 0, names = "clear"),
                                 limits = c(-0.5, 1.2)) +
              xlab("Longitude") + ylab("Latitude") +
              theme(legend.position = "top") + 
              guides(fill = guide_colourbar(title = "Temperature \n anomaly")) +
              geom_sf(data = snaps_av, mapping = aes(fill = anom), alpha = 0.8) + 
              coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
              theme(axis.title = element_text(size = 12)) +
              theme(legend.background = element_rect(fill = "transparent"))
```

```{r anomaly-trend, echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center", fig.width = 7.5, fig.height = 4.8, fig.cap = "Average spring temperature anomaly for the period 1995-2020 compared to a baseline period of 1951-1980. All cells with breeding records are included. Small panels show the historical trend in spring temperature anomaly for cells in four equal latitude bands. Lines are smoothed fits and standard errors from generalized additive models for illustration. The solid dashed line indicates the baseline average spring temperature for the reference period."}
# Plot change in historic cold snaps split by latitude
        anom_change <- ggplot(data = snaps3, mapping = aes(x = year, y = spring_anomaly, fill = grp2, color = grp2)) +
          #scale_fill_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          #scale_color_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          geom_hline(yintercept = 0, linetype = "dashed") +
          geom_smooth(color = "coral3", fill = "coral3") + theme_bw() +
          ylab("Spring temperature anomaly 1995-2020") +
          xlab("Year") +
          theme(axis.title = element_text(size = 16)) +
          facet_wrap(~ grp2, nrow = 4, strip.position = "top") +
          guides(fill = FALSE, color = FALSE) +
          #theme(strip.background = element_blank(), strip.text = element_blank()) +
        theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
          xlim(1920, 2017)

        anom_supp <- ggarrange(p_anom, anom_change, nrow = 1, widths = c(2.5, 1))
        saveRDS(anom_supp, here::here("4_output_figures", "anom_supp.rds"))
```

```{r heat-plot, echo = FALSE, message = FALSE, warning = FALSE}
# Convert to a long term average date of last cold snap for each grid
          snaps95 <- subset(snaps, snaps$year > 1994)
          snaps_av <- snaps95 %>%
            group_by(id) %>%
            dplyr::summarise(mu_1d = mean(subset(first_1d26, heat_1d_26 == "Yes"), na.rm = TRUE), 
                             mu_2d = mean(subset(first_2d26, heat_2d_26 == "Yes"), na.rm = TRUE), 
                             mu_3d = mean(subset(first_3d26, heat_3d_26 == "Yes"), na.rm = TRUE),
                             anom_3d = mean(a_1d26, na.rm = TRUE))
            
            # p3d <- ggplot(data = snaps_av) + geom_sf(data = namer, fill = "gray75") +
            #   theme_bw() +
            #   #xlim(c(-130, -66)) + ylim(c(22, 58)) +
            #   scale_fill_viridis(alpha = 0.8, option = "inferno", direction = -1) +
            #   xlab("Longitude") + ylab("Latitude") +
            #   theme(legend.position = "top") +
            #   guides(fill = guide_colourbar(title = "Day of \n year")) +
            #   geom_sf(data = snaps_av, mapping = aes(fill = mu_3d), alpha = 0.7) +
            #   coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
            #   theme(axis.title = element_text(size = 16)) +
            #   theme(legend.background = element_rect(fill = "transparent"))
            
            p_heat_avg <- ggplot(data = snaps_av) + geom_sf(data = namer, fill = "gray75") + 
              theme_bw() +
              #scale_fill_viridis(alpha = 0.8, option = "inferno", direction = -1) + 
              scale_fill_gradient2(high = "#E66101", low = "#0571B0", mid = "#F7F7F7", midpoint = 0,
                   na.value = rgb(211, 211, 211, max = 255, alpha = 0.4, names = "clear"),
                   #na.value = rgb(115, 230, 67, max = 255, alpha = 0.05, names = "clear"),
                   limits = c(-22, 12)) +
              xlab("Longitude") + ylab("Latitude") +
              theme(legend.position = "top") + 
              guides(fill = guide_colourbar(title = "Heat-wave \n anomaly")) +
              geom_sf(data = snaps_av, mapping = aes(fill = anom_3d), alpha = 0.8) + 
              coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], bb["ymax"])) +
              theme(axis.title = element_text(size = 12)) +
              theme(legend.background = element_rect(fill = "transparent"))
              
            
            #p3d2 <- p3d + geom_sf(data = grid2, fill = "blue") +
            #  geom_sf_text(data = grid2, aes(label = id), color = "white")
            
            #p3d3 <- p3d + geom_sf_text(data = snaps_av, aes(label = id), color = "white")
            
```

```{r heat-trend, echo = FALSE, warning = FALSE, message = FALSE, fig.align = "center", fig.width = 7.5, fig.height = 4.8, fig.cap = "Average date of the earliest three day period in which daytime temperatures rose above 26 degrees from 1995-2020. All cells with breeding records are included; gray cells did not have sufficient historical temperature data to calculate cold snaps. Small panels show the historical trend in the timing of cold snaps for cells in four equal latitude bands as an anomaly from the average cold snap date between 1951-1980; latitude ranges are listed in the header of each panel. Lines show smoothed fits and standard errors from generalized additive models for illustration. The solid dashed line indicates the baseline average cold snap date. Points below the line show years where the last cold snap occurs earlier than the baseline and points above show years where the last cold snap occurs later than the baseline."}
# Builds on previous chunk looking at historic change in cold snap timing
    # Group hexagons by latitude of centroid
        snaps2 <- snaps
        snaps2$centroid <- st_centroid(snaps$geometry)
        st_geometry(snaps2) <- "centroid"
        snaps2 <- st_transform(snaps2, st_crs(namer_o))
        
        centers <- data.frame(st_coordinates(snaps2))
        snaps2$lat <- centers$Y
        snaps2$long <- centers$X
    # Now convert back to abers
        snaps3 <- st_transform(snaps2, proj_code)
    
        
    # cut into four groups by latitude    
        snaps3$grp <- cut(snaps3$lat, 4)
        snaps3 <- subset(snaps3, is.na(snaps3$lat) == FALSE)
        snaps3$grp <- factor(snaps3$grp, levels = c("(49.9,58.1]", "(41.6,49.9]", "(33.4,41.6]","(25.2,33.4]"))
        sngrp <- data.frame(grp = c("(49.9,58.1]", "(41.6,49.9]", "(33.4,41.6]","(25.2,33.4]"),
                            grp2 = c("(50-58)", "(42-50)", "(33-42)", "(25-33)"))
        snaps3 <- left_join(snaps3, sngrp, "grp")
        snaps3$grp2 <- factor(snaps3$grp2, levels = c("(50-58)", "(42-50)", "(33-42)", "(25-33)"))
        
    # Plot change in historic cold snaps split by latitude
        heat_change <- ggplot(data = snaps3, mapping = aes(x = year, y = a_3d26, fill = grp2, color = grp2)) +
          #scale_fill_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          #scale_color_viridis(discrete = TRUE, option = "inferno", begin = 0.1, end = 0.85) +
          geom_hline(yintercept = 0, linetype = "dashed") +
          geom_smooth(color = "coral3", fill = "coral3") + theme_bw() +
          ylab("3-day heat-wave anomaly") +
          xlab("Year") +
          theme(axis.title = element_text(size = 16)) +
          facet_wrap(~ grp2, nrow = 4, strip.position = "top") +
          guides(fill = FALSE, color = FALSE) +
          #theme(strip.background = element_blank(), strip.text = element_blank()) +
        theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
          coord_cartesian(ylim = c(-15, 15), xlim = c(1920, 2017))
          
        
        heat_anom <- ggarrange(p_heat_avg, heat_change, nrow = 1, widths = c(2.5, 1))
        saveRDS(heat_anom, here::here("4_output_figures", "heat_anom.rds"))
        
        # Save the three small maps for inclusion in manuscript
          delta_temp_plot <- ggarrange(p_anom + annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "A", fontface = 2),
                                       p_anom_avg + annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "B", fontface = 2),
                                       p_heat_avg + annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "C", fontface = 2),
                                       nrow = 1)
          saveRDS(delta_temp_plot, here::here("4_output_figures", "delta_temp_plot.rds"))
          
    
```

```{r overall-trend, echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE, fig.align = "center", fig.width = 4, fig.height = 7, fig.cap = "Overall trend for (A) spring temperature anomaly and (B) date of the last three day cold snap over the last 100 years. Smoothed lines are plotted from a generalized additive model that included a spatial smooth with latitude and longitude to account for spatial autocorrelation."}
# GAM examples: https://noamross.github.io/gams-in-r-course/chapter3
# GAM plotting: https://cran.r-project.org/web/packages/tidymv/vignettes/predict-gam.html


# Fit overall GAMs for anomaly and cold snap dates
        m_anom <- gam(spring_anomaly ~ s(c_long, c_lat) + s(year), data = snaps, method = "REML")
        
        # pred_anom <- predict_gam(m_anom, length_out = 100)
        # pred_anom <- pred_anom %>%
        #   group_by(year) %>%
        #   summarise(fit = mean(fit), se.fit = mean(se.fit))
        # pred_anom$upper <- pred_anom$fit + 1.96*pred_anom$se.fit
        # pred_anom$lower <- pred_anom$fit - 1.96*pred_anom$se.fit
        
        # pred_anom <- predict_gam(m_anom, exclude_terms = "s(c_long, c_lat)", length_out = 100, values = list(c_lat = NULL, c_long = NULL))
        # pred_anom$upper <- pred_anom$fit + 1.96*pred_anom$se.fit
        # pred_anom$lower <- pred_anom$fit - 1.96*pred_anom$se.fit
  
  pred_anom <- predict_gam(m_anom, length_out = 100, exclude_terms = "s(c_long,c_lat)")
  pred_anom <- pred_anom %>%
    dplyr::group_by(year) %>%
    dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
  pred_anom$upper <- pred_anom$fit + 1.96*pred_anom$se.fit
  pred_anom$lower <- pred_anom$fit - 1.96*pred_anom$se.fit
  
  anom_overall <- ggplot(data = pred_anom, mapping = aes(x = year, y = fit)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    #geom_smooth_ci(color = "coral3") +
    xlab("Year") + ylab("Spring temperature\n anomaly (\u00B0C)") +
    theme_classic() +
    theme(axis.title = element_text(size = 14)) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    coord_cartesian(xlim = c(1917, 2017)) +
    geom_line(color = "coral3", size = 1) +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.4, fill = "coral3", color = "transparent") +
    annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "A")
  
  
# cold snap  
  # 18.5 C
      m_snap <- gam(a_3d18 ~ s(c_long, c_lat) + s(year), data = snaps, method = "REML")
      snap_anom <- predict_gam(m_snap, length_out = 100, exclude_terms = "s(c_long,c_lat)")
      snap_anom <- snap_anom %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      snap_anom$upper <- snap_anom$fit + 1.96*snap_anom$se.fit
      snap_anom$lower <- snap_anom$fit - 1.96*snap_anom$se.fit
    # 16 C
      m_snap16 <- gam(a_3d16 ~ s(c_long, c_lat) + s(year), data = snaps, method = "REML")
      snap_anom16 <- predict_gam(m_snap16, length_out = 100, exclude_terms = "s(c_long,c_lat)")
      snap_anom16 <- snap_anom16 %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      snap_anom16$upper <- snap_anom16$fit + 1.96*snap_anom16$se.fit
      snap_anom16$lower <- snap_anom16$fit - 1.96*snap_anom16$se.fit
    # 13.5 C
      m_snap13 <- gam(a_3d13 ~ s(c_long, c_lat) + s(year), data = snaps, method = "REML")
      snap_anom13 <- predict_gam(m_snap13, length_out = 100, exclude_terms = "s(c_long,c_lat)")
      snap_anom13 <- snap_anom13 %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      snap_anom13$upper <- snap_anom13$fit + 1.96*snap_anom13$se.fit
      snap_anom13$lower <- snap_anom13$fit - 1.96*snap_anom13$se.fit
  # plot
    snap_overall <- ggplot(data = snap_anom, mapping = aes(x = year, y = fit)) +
      geom_hline(yintercept = 0, linetype = "dashed") +
      #geom_smooth_ci(color = "coral3") +
      xlab("Year") + ylab("Last cold-snap\n anomaly (days)") +
      theme_classic() +
      theme(axis.title = element_text(size = 14)) +
      theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
      coord_cartesian(xlim = c(1917, 2017)) +
      geom_line(aes(color = "17.4"), size = 1) +
      geom_ribbon(aes(ymin = lower, ymax = upper, fill = '17.4'), alpha = 0.4, color = "transparent") +
      geom_line(data = snap_anom16, aes(color = "15.5"), size = 1) +
      geom_ribbon(data = snap_anom16, aes(ymin = lower, ymax = upper, fill = '15.5'), alpha = 0.4, color = "transparent") +
      geom_line(data = snap_anom13, aes(color = "13.9"), size = 1) +
      geom_ribbon(data = snap_anom13, aes(ymin = lower, ymax = upper, fill = '13.9'), alpha = 0.4, color = "transparent") +
      scale_fill_manual(name = "",
                        breaks = c('17.4', '15.5', '13.9'),
                        values = c('17.4' = '#E69F00', '15.5' = '#56B4E9', '13.9' = '#CC79A7'),
                        labels = c('17.4' = expression(paste("17.4 ", ~degree*C)),
                               '15.5' = expression(paste("15.5 ", ~degree*C)),
                               '13.9' = expression(paste("13.9 ", ~degree*C)))) +
      scale_color_manual(name = "",
                         breaks = c('17.4', '15.5', '13.9'),
                         values = c('17.4' = '#E69F00', '15.5' = '#56B4E9', '13.9' = '#CC79A7'),
                         labels = c('17.4' = expression(paste("17.4 ", ~degree*C)),
                                '15.5' = expression(paste("15.5 ", ~degree*C)),
                                '13.9' = expression(paste("13.9 ", ~degree*C)))) +
      guides(fill = "none") +
      annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B") +
      theme(legend.position = c(0.7, 0.2), legend.background = element_rect(fill = "transparent"))
    
  
# heat-wave 
    # note that even though columns list 26/31/36 the actual temperature thresholds used
    # are 26/29/32 and are set above in the historical anomaly block
    
  # 26 C
      m_wave <- gam(a_3d26 ~ s(year) + s(c_long, c_lat), data = snaps, method = "REML")
      wave_anom <- predict_gam(m_wave, length_out = 100)
      wave_anom <- wave_anom %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      wave_anom$upper <- wave_anom$fit + 1.96*wave_anom$se.fit
      wave_anom$lower <- wave_anom$fit - 1.96*wave_anom$se.fit
    # 29 C
      m_wave31 <- gam(a_3d31 ~ s(c_long, c_lat) + s(year), data = snaps, method = "REML")
      wave_anom31 <- predict_gam(m_wave31, length_out = 100)
      wave_anom31 <- wave_anom31 %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      wave_anom31$upper <- wave_anom31$fit + 1.96*wave_anom31$se.fit
      wave_anom31$lower <- wave_anom31$fit - 1.96*wave_anom31$se.fit
    # 31 C
      m_wave36 <- gam(a_3d36 ~ s(year), data = snaps, method = "REML")
      wave_anom36 <- predict_gam(m_wave36, length_out = 100)
      wave_anom36 <- wave_anom36 %>%
        dplyr::group_by(year) %>%
        dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
      wave_anom36$upper <- wave_anom36$fit + 1.96*wave_anom36$se.fit
      wave_anom36$lower <- wave_anom36$fit - 1.96*wave_anom36$se.fit
      
      wave_anom36 <- get_gam_predictions(m_wave36, year, series_length = 100)
      wave_anom36$fit <- wave_anom36$a_3d36
      
  # plot
    wave_overall <- ggplot(data = wave_anom, mapping = aes(x = year, y = fit)) +
      geom_hline(yintercept = 0, linetype = "dashed") +
      #geom_smooth_ci(color = "coral3") +
      xlab("Year") + ylab("First heat-wave\n anomaly (days)") +
      theme_classic() +
      theme(axis.title = element_text(size = 14)) +
      theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
      coord_cartesian(xlim = c(1917, 2017)) +
      geom_line(aes(color = '32.1'), size = 1) +
      geom_ribbon(aes(ymin = lower, ymax = upper, fill = '32.1'), alpha = 0.4, color = "transparent") +
      geom_line(data = wave_anom31, aes(color = '33.6'), size = 1) +
      geom_ribbon(data = wave_anom31, aes(ymin = lower, ymax = upper, fill = '33.6'), alpha = 0.4, color = "transparent") +
      geom_line(data = wave_anom36, aes(color = '34.8'), size = 1) +
      geom_ribbon(data = wave_anom36, aes(ymin = CI_lower, ymax = CI_upper, fill = '34.8'), alpha = 0.4, color = "transparent") +
      scale_fill_manual(name = "",
                        breaks = c('32.1', '33.6', '34.8'),
                        values = c('32.1' = '#E69F00', '33.6' = '#56B4E9', '34.8' = '#CC79A7'),
                         labels = c('32.1' = expression(paste("32.1 ", ~degree*C)),
                                '33.6' = expression(paste("33.6 ", ~degree*C)),
                                '34.8' = expression(paste("34.8 ", ~degree*C)))) +
      scale_color_manual(name = "",
                         breaks = c('32.1', '33.6', '34.8'),
                         values = c('32.1' = '#E69F00', '33.6' = '#56B4E9', '34.8' = '#CC79A7'),
                         labels = c('32.1' = expression(paste("32.1 ", ~degree*C)),
                                '33.6' = expression(paste("33.6 ", ~degree*C)),
                                '34.8' = expression(paste("34.8 ", ~degree*C)))) +
      guides(fill = "none") +
      annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "C") +
      theme(legend.position = c(0.82, 0.2), legend.background = element_rect(fill = "transparent"))

## save models
    time_series_mods <- list(m_anom, m_snap, m_snap16, m_snap13, m_wave, m_wave31, m_wave36)
    saveRDS(time_series_mods, here::here("6_saved_data_objects", "time_series_mods.rds"))
        
## combine plot    
  
  anom_trend <- ggarrange(anom_overall, snap_overall, wave_overall, nrow = 1)
  
  saveRDS(anom_trend, here::here("4_output_figures", "anom_trend.rds"))

```

```{r snap-anomaly, echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center", fig.width = 7.4, fig.height = 5.7, fig.cap = "Spring average temperature anomaly in relation to the date of the last three day cold snap. Grid shows the count of total cell level observations at each combination with all years counted. Red line is a fit from a GAM that includes a basis spline for year and tensor smooth for latitude and longitude to account for spatial and temporal autocorrelation. Shaded red region shows the 95% confidence interval of the fit GAM. Data are plotted from period 1995-2020."}

snap_anom <- gam(a_3d18 ~ s(spring_anomaly) + s(c_long, c_lat) + s(year), data = snaps95, method = "REML")
pred_sa <- predict_gam(snap_anom)
pred_sa <- pred_sa %>%
 dplyr::group_by(spring_anomaly) %>%
 dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
pred_sa$upper <- pred_sa$fit + 1.96*pred_sa$se.fit
pred_sa$lower <- pred_sa$fit - 1.96*pred_sa$se.fit

saveRDS(snap_anom, here::here("6_saved_data_objects/snap_anom.rds"))
saveRDS(pred_sa, here::here("6_saved_data_objects/cold_anom_model.rds"))
pred_sa <- readRDS(here::here("6_saved_data_objects/cold_anom_model.rds"))

heat_anom <- gam(a_3d26 ~ s(spring_anomaly) + s(c_long, c_lat) + s(year), data = snaps95, method = "REML")
pred_ha <- predict_gam(heat_anom)
pred_ha <- pred_ha %>%
 dplyr::group_by(spring_anomaly) %>%
 dplyr::summarise(fit = mean(fit), se.fit = mean(se.fit))
pred_ha$upper <- pred_ha$fit + 1.96*pred_ha$se.fit
pred_ha$lower <- pred_ha$fit - 1.96*pred_ha$se.fit

saveRDS(heat_anom, here::here("6_saved_data_objects/heat_anom.rds"))
saveRDS(pred_ha, here::here("6_saved_data_objects/heat_anom_model.rds"))
pred_ha <- readRDS(here::here("6_saved_data_objects/heat_anom_model.rds"))


sa_plot <- ggplot(data = pred_sa, mapping = aes(x = spring_anomaly, y = fit)) +
  geom_hex(data = snaps, mapping = aes(x = spring_anomaly, y = a_3d18, fill = stat(log(count))), bins = 75, alpha = 0.7) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_fill_viridis() +
  #geom_smooth_ci(color = "coral3") +
  coord_cartesian(xlim = c(-3.7, 4), ylim = c(-70, 60)) +
  theme_bw() +
  xlab("Spring temperature anomaly") +
  ylab("Last 3-day\n cold snap anomaly") +
  #guides(fill = FALSE, color = FALSE) +
  theme(axis.title = element_text(size = 16)) +
  geom_line(color = "coral3", size = 1.5) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.4, fill = "coral3", color = "transparent") +
  theme(panel.grid = element_blank()) +
  scale_y_continuous(breaks = seq(-100, 100, 20)) +
  theme(legend.position = "top") +
  annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "A")

ha_plot <- ggplot(data = pred_ha, mapping = aes(x = spring_anomaly, y = fit)) +
  geom_hex(data = snaps, mapping = aes(x = spring_anomaly, y = a_3d26, fill = stat(log(count))), bins = 75, alpha = 0.7) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_fill_viridis() +
  #geom_smooth_ci(color = "coral3") +
  coord_cartesian(xlim = c(-3.7, 4), ylim = c(-70, 60)) +
  theme_bw() +
  xlab("Spring temperature anomaly") +
  ylab("First 3-day\n heat wave anomaly") +
  #guides(fill = FALSE, color = FALSE) +
  theme(axis.title = element_text(size = 16)) +
  geom_line(color = "coral3", size = 1.5) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.4, fill = "coral3", color = "transparent") +
  theme(panel.grid = element_blank()) +
  scale_y_continuous(breaks = seq(-100, 100, 20)) +
  theme(legend.position = "top") +
  annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B")

hex_plot <- ggarrange(sa_plot, ha_plot, nrow = 1)
saveRDS(hex_plot, here::here("4_output_figures", "hex_plot.rds"))


```

```{r snap-anom95, echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center", fig.width = 4.5, fig.height = 4.5, fig.cap = "Average spring temperature anomaly versus average cold snap anomaly from 1995-2020. Points are raw data for each hexagon grid. Red line and confidence interval are from a GAM with a tensor smooth to account for spatial autocorrelation."}

# summarise to averages for each grid from 1995-2020
  sn95 <- snaps95 %>% 
    dplyr::group_by(id) %>% 
    dplyr::summarise(mu_temp = mean(spring_anomaly, na.rm = TRUE), mu_cold = mean(a_3d18, na.rm = TRUE), mu_heat = mean(a_3d26, na.rm = TRUE))

  sn95$centroid <- st_centroid(sn95)
  cts <- st_coordinates(sn95$centroid)
  sn95$c_long <- cts[, 1]
  sn95$c_lat <- cts[, 2]
  sn95 <- st_drop_geometry(sn95)
  sn95 <- sn95[, c("id", "mu_temp", "mu_cold", "mu_heat", "c_long", "c_lat")]
  
  m_sn95 <- gam(mu_cold ~ s(mu_temp) + s(c_long, c_lat), data = sn95)
  
  pr_sn95 <- predict_gam(m_sn95)
  pr_sn95_2 <- pr_sn95 %>%
    dplyr::group_by(mu_temp) %>%
    dplyr::summarise(fit = mean(fit, na.rm = TRUE), se.fit = mean(se.fit, na.rm = TRUE))
  pr_sn95_2$upper <- pr_sn95_2$fit + 1.96*pr_sn95_2$se.fit
  pr_sn95_2$lower <- pr_sn95_2$fit - 1.96*pr_sn95_2$se.fit
  
  m_hw95 <- gam(mu_heat ~ s(mu_temp) + s(c_long, c_lat), data = sn95)
  
  pr_hw95 <- predict_gam(m_hw95)
  pr_hw95_2 <- pr_hw95 %>%
    dplyr::group_by(mu_temp) %>%
    dplyr::summarise(fit = mean(fit, na.rm = TRUE), se.fit = mean(se.fit, na.rm = TRUE))
  pr_hw95_2$upper <- pr_hw95_2$fit + 1.96*pr_hw95_2$se.fit
  pr_hw95_2$lower <- pr_hw95_2$fit - 1.96*pr_hw95_2$se.fit
  
  # save models
      saveRDS(m_sn95, here::here("6_saved_data_objects", "m_sn95.rds"))
      saveRDS(m_hw95, here::here("6_saved_data_objects", "m_hw95.rds"))
  
  cold_mu <- ggplot(data = sn95, mapping = aes(x = mu_temp, y = mu_cold)) +
    geom_point(color = "slateblue", alpha = 0.5) +
    theme_classic() +
    theme(axis.title = element_text(size = 16)) +
    #geom_hline(yintercept = 0, linetype = "dashed", color = "gray20") +
    #geom_vline(xintercept = 0, linetype = "dashed") +
    xlab("Average spring temperature \n anomaly 1995-2020 (\u00B0C)") +
    ylab("Average cold snap \n anomaly 1995-2020 (days)") +
    coord_cartesian(ylim = c(-25, 15), xlim = c(0.1, 1.05)) +
    annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "A") +
    geom_ribbon(data = pr_sn95_2, mapping = aes(x = mu_temp, y = fit, ymin = lower, ymax = upper), 
                fill = "slateblue", alpha = 0.3, color = "transparent") +
    geom_line(data = pr_sn95_2, mapping = aes(x = mu_temp, y = fit), color = "slateblue", size = 1.5) 
    #geom_smooth(color = "gray30", linetype = "dashed", fill = "gray30", alpha = 0.2)
  
  
  heat_mu <- ggplot(data = sn95, mapping = aes(x = mu_temp, y = mu_heat)) +
    geom_point(color = "coral3", alpha = 0.5) +
    theme_classic() +
    theme(axis.title = element_text(size = 16)) +
    #geom_hline(yintercept = 0, linetype = "dashed", color = "gray20") +
    coord_cartesian(ylim = c(-20, 20), xlim = c(0.1, 1.05)) +
    annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B") +
    #geom_vline(xintercept = 0, linetype = "dashed") +
    xlab("Average spring temperature \n anomaly 1995-2020 (\u00B0C)") +
    ylab("Average heat wave \n anomaly 1995-2020 (days)") +
    geom_ribbon(data = pr_hw95_2, mapping = aes(x = mu_temp, y = fit, ymin = lower, ymax = upper), 
                fill = "coral3", alpha = 0.3, color = "transparent") +
    geom_line(data = pr_hw95_2, mapping = aes(x = mu_temp, y = fit), color = "coral3", size = 1.5) 
  
  overall <- ggarrange(cold_mu, heat_mu, nrow = 1)
  saveRDS(overall, here::here("4_output_figures", "overall_plot.rds"))

```

## Breeding records

```{r anom-breed, echo = FALSE, message = FALSE, warning = FALSE}
## Combine breeding records and grid level temperature records
  ds_g <- st_join(dsfo, grid2)
  ds_g <- st_drop_geometry(ds_g)
  ds_g$fledged_yn <- ifelse(ds_g$young_fled_atleast > 0, 1, 0)
  ds_g2 <- ds_g %>%
    group_by(year, alpha4, id, aerial) %>%
    summarize(n_gy = n(), mu_fled = mean(young_fled_atleast, na.rm = TRUE), mu_clutch = mean(clutch_host_atleast, na.rm = TRUE),
              mu_hatch_doy = mean(hatch_doy), num_fled = sum(fledged_yn))
  ds_g2 <- subset(ds_g2, ds_g2$n_gy > 4)
  
  ds_g2$y_id <- paste(ds_g2$id, ds_g2$year, sep = "_")
  snaps95$y_id <- paste(snaps95$id, snaps95$year, sep = "_")
  
  ds_g3 <- right_join(snaps95, ds_g2, "y_id")
  
# not using these  
  # m <- lmer(mu_fled ~ aerial*a_3d13 + (1|id.y), data = ds_g3)
  # m2 <- glmer(cbind(num_fled, (n_gy - num_fled)) ~ a_3d13*spring_anomaly + (1|alpha4) + (1|id.y), data = subset(ds_g3, ds_g3$aerial == "yes"), family = "binomial")
  # 
  #   m3 <- glmer(cbind(num_fled, (n_gy - num_fled)) ~ a_3d18*aerial + (1|alpha4) + (1|id.y), data = ds_g3, family = "binomial")
  # 
  # mg <- gam(num_fled / n_gy ~ s(a_3d13) + s(c_long, c_lat) + s(year.x), data = subset(ds_g3, ds_g3$aerial == "yes"))

```

```{r breeding-temp, echo = FALSE, message = FALSE, warning = FALSE}

# This is all adding temperature records to breeding records. It takes a while to run so I've saved the otput and reloaded it.
# colnames(tem95)[1] <- "stn_id"
# stn_list <- unique(dsfo$stn_id)
# tem95x <- tem95[tem95$stn_id %in% stn_list, ]
# 
# dsfo$c_long <- st_coordinates(dsfo)[, 1]
# dsfo$c_lat <- st_coordinates(dsfo)[, 2]
# dsfo2 <- st_drop_geometry(dsfo)
# 
# begin <- Sys.time()
# for(i in 1995:2020){
#   tem_y <- subset(tem95x, tem95x$year == i)
#   dssub <- subset(dsfo2, dsfo2$year == i)
#   for(j in 1:nrow(dssub)){
#     ts1 <- subset(tem_y, tem_y$stn_id == dssub$stn_id[j])
#     ts_inc <- subset(ts1, ts1$doy > (dssub$hatch_doy[j] - dssub$incu_days[j]) &
#                        ts1$doy <= dssub$hatch_doy[j])
#     ts_nes <- subset(ts1, ts1$doy >= dssub$hatch_doy[j] &
#                      ts1$doy <= (dssub$hatch_doy[j] + dssub$nest_days[j]))
#      ts_all <- subset(ts1, ts1$doy > (dssub$hatch_doy[j] - dssub$incu_days[j]) &
#                         ts1$doy <= (dssub$hatch_doy[j] + dssub$nest_days[j]))
#     dssub$min_3_inc[j] <- min(na.omit(frollapply(ts_inc$value / 10, 3, max)))
#     dssub$min_3_nes[j] <- min(na.omit(frollapply(ts_nes$value / 10, 3, max)))
#     dssub$max_3_inc[j] <- max(na.omit(frollapply(ts_inc$value / 10, 3, min)))
#     dssub$max_3_nes[j] <- max(na.omit(frollapply(ts_nes$value / 10, 3, min)))
#      dssub$min_3_all[j] <- min(na.omit(frollapply(ts_all$value / 10, 3, max)))
#      dssub$max_3_all[j] <- max(na.omit(frollapply(ts_all$value / 10, 3, min)))
#   }
#   if(i == 1995){dsfo_tem <- dssub}
#   if(i > 1995){dsfo_tem <- rbind(dsfo_tem, dssub)}
#   print(i)
# }
# end <- Sys.time()
# end - begin

#saveRDS(dsfo_tem, here::here("6_saved_data_objects/record_and_temps.rds"))
dsfo_tem <- readRDS(here::here("6_saved_data_objects/record_and_temps.rds"))

# ## Add cold snap at per grid level (instead of station)
  # stnlist <- sd4[sd4$id %in% grid2$id, ]
  # tem95g <- tem95[tem95$stn_id %in% unique(stnlist$stn_id), ]
  # 
  # stnlist <- st_drop_geometry(stnlist)
  # tem95g <- plyr::join(tem95g, stnlist, "stn_id")
  # 
  # dsg <- st_join(dsfo, grid2)

# begin <- Sys.time()
#   for(i in 1995:2020){
#     tem95g_s <- subset(tem95g, tem95g$year == i)
#     tem95g_s2 <- tem95g_s %>%
#       dplyr::group_by(id, doy) %>%
#       dplyr::summarise(mu_maxt = mean(value / 10, na.rm = TRUE), n_stns = n())
# 
#     dssub <- subset(dsg, dsg$year == i)
#     for(j in 1:nrow(dssub)){
#       ts1 <- subset(tem95g_s2, tem95g_s2$id == dssub$id[j])
#       ts_inc <- subset(ts1, ts1$doy > (dssub$hatch_doy[j] - dssub$incu_days[j]) &
#                          ts1$doy <= dssub$hatch_doy[j])
#       ts_nes <- subset(ts1, ts1$doy >= dssub$hatch_doy[j] &
#                        ts1$doy <= (dssub$hatch_doy[j] + dssub$nest_days[j]))
#        ts_all <- subset(ts1, ts1$doy > (dssub$hatch_doy[j] - dssub$incu_days[j]) &
#                           ts1$doy <= (dssub$hatch_doy[j] + dssub$nest_days[j]))
#       dssub$min_3g_inc[j] <- min(na.omit(frollapply(ts_inc$mu_maxt, 3, max)))
#       dssub$min_3g_nes[j] <- min(na.omit(frollapply(ts_nes$mu_maxt, 3, max)))
#       dssub$max_3g_inc[j] <- max(na.omit(frollapply(ts_inc$mu_maxt, 3, min)))
#       dssub$max_3g_nes[j] <- max(na.omit(frollapply(ts_nes$mu_maxt, 3, min)))
#        dssub$min_3g_all[j] <- min(na.omit(frollapply(ts_all$mu_maxt, 3, max)))
#        dssub$max_3g_all[j] <- max(na.omit(frollapply(ts_all$mu_maxt, 3, min)))
#     }
#     if(i == 1995){dsfo_temg <- dssub}
#     if(i > 1995){dsfo_temg <- rbind(dsfo_temg, dssub)}
#     print(i)
#   }
#  end <- Sys.time()
#  end - begin

dsfo_tem$elev_diff <- abs(dsfo_tem$elevation - dsfo_tem$stn_elev)
dsfo_tem <- subset(dsfo_tem, dsfo_tem$stn_dist < 50000 & dsfo_tem$elev_diff < 500)

# 
# 
# saveRDS(dsfo_temg, here::here("6_saved_data_objects/records_and_temps_grid.rds"))
# dsfo_temg <- readRDS(here::here("6_saved_data_objects/records_and_temps_grid.rds"))
# dsfo_temg2 <- st_drop_geometry(dsfo_temg)
# 
# dsfo_temg$c_long <- st_coordinates(dsfo_temg)[, 1]
# dsfo_temg$c_lat <- st_coordinates(dsfo_temg)[, 2]

# does not work with missing (non finite) values
  # dsfo_temg2 <- dsfo_temg2 %>%
  #   filter(is.finite(min_3g_inc), is.finite(min_3g_nes), is.finite(max_3g_inc), is.finite(max_3g_nes),
  #          is.finite(min_3g_all), is.finite(max_3g_all))
  
  dsfo_tem2 <- dsfo_tem %>%
    filter(is.finite(min_3_inc), is.finite(min_3_nes), is.finite(max_3_inc), is.finite(max_3_nes),
           is.finite(min_3_all), is.finite(max_3_all))

# standardize hottest and coldest and fitness by species
    # dsfo_temg2$s_young_fled_atleast <- transform(dsfo_temg2, s_young_fled_atleast = ave(young_fled_atleast, common_name, FUN = scale))$s_young_fled_atleast
    # dsfo_temg2$s_min_3g_inc <- transform(dsfo_temg2, s_min_3g_inc = ave(min_3g_inc, common_name, FUN = scale))$s_min_3g_inc
    # dsfo_temg2$s_min_3g_nes <- transform(dsfo_temg2, s_min_3g_nes = ave(min_3g_nes, common_name, FUN = scale))$s_min_3g_nes
    # dsfo_temg2$s_max_3g_inc <- transform(dsfo_temg2, s_max_3g_inc = ave(max_3g_inc, common_name, FUN = scale))$s_max_3g_inc
    # dsfo_temg2$s_max_3g_nes <- transform(dsfo_temg2, s_max_3g_nes = ave(max_3g_nes, common_name, FUN = scale))$s_max_3g_nes
    # dsfo_temg2$s_min_3g_all <- transform(dsfo_temg2, s_min_3g_all = ave(min_3g_all, common_name, FUN = scale))$s_min_3g_all
    # dsfo_temg2$s_max_3g_all <- transform(dsfo_temg2, s_max_3g_all = ave(max_3g_all, common_name, FUN = scale))$s_max_3g_all
    
    dsfo_tem2$s_young_fled_atleast <- transform(dsfo_tem2, s_young_fled_atleast = ave(young_fled_atleast, common_name, FUN = scale))$s_young_fled_atleast
    dsfo_tem2$s_min_3_inc <- transform(dsfo_tem2, s_min_3_inc = ave(min_3_inc, common_name, FUN = scale))$s_min_3_inc
    dsfo_tem2$s_min_3_nes <- transform(dsfo_tem2, s_min_3_nes = ave(min_3_nes, common_name, FUN = scale))$s_min_3_nes
    dsfo_tem2$s_max_3_inc <- transform(dsfo_tem2, s_max_3_inc = ave(max_3_inc, common_name, FUN = scale))$s_max_3_inc
    dsfo_tem2$s_max_3_nes <- transform(dsfo_tem2, s_max_3_nes = ave(max_3_nes, common_name, FUN = scale))$s_max_3_nes
    dsfo_tem2$s_min_3_all <- transform(dsfo_tem2, s_min_3_all = ave(min_3_all, common_name, FUN = scale))$s_min_3_all
    dsfo_tem2$s_max_3_all <- transform(dsfo_tem2, s_max_3_all = ave(max_3_all, common_name, FUN = scale))$s_max_3_all
    
    
# add relative fitness
    # d_temp <- dsfo_temg2 %>%
    #   group_by(common_name) %>%
    #   summarise(mean_fitness = mean(young_fled_atleast, na.rm = TRUE))
    # dsfo_temg2 <- plyr::join(dsfo_temg2, d_temp, "common_name", "left", "first")
    # dsfo_temg2$w_fitness <- dsfo_temg2$young_fled_atleast / dsfo_temg2$mean_fitness
    
    d_temp2 <- dsfo_tem2 %>%
      dplyr::group_by(common_name) %>%
      dplyr::summarise(mean_fitness = mean(young_fled_atleast, na.rm = TRUE))
    
    d_temp2b <- dsfo_tem2 %>%
      filter(young_host_atleast > 0) %>%
      dplyr::group_by(common_name) %>%
      dplyr::summarise(mean_fitness_hatched = mean(young_fled_atleast, na.rm = TRUE))
    
    
    dsfo_tem2 <- plyr::join(dsfo_tem2, d_temp2, "common_name", "left", "first")
    dsfo_tem2 <- plyr::join(dsfo_tem2, d_temp2b, "common_name", "left", "first")
    
    dsfo_tem2$w_fitness <- dsfo_tem2$young_fled_atleast / dsfo_tem2$mean_fitness
    dsfo_tem2$w_fitness_b <- dsfo_tem2$young_fled_atleast / dsfo_tem2$mean_fitness_hatched

# summary plot just looking at trends with cold. Not used.
# p1 <- ggplot(data = dsfo_tem, mapping = aes(x = min_3_nes, y = young_fled_atleast, color = a_cav, fill = a_cav)) +
#   #geom_hex(binx = 50, alpha = 0.3) +
#   #geom_point(color = "black", alpha = 0.2) +
#   geom_point(color = "gray", size = 0.5, alpha = 0.1) +
#   geom_smooth() +
#   scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +
#   scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +
#   facet_wrap(~ common_name, nrow = 4, ncol = 6, scale = "free") +
#   theme_bw() +
#   #xlim(0, 40) +
#   guides(fill = FALSE, color = FALSE)
# 
# 
# p2 <- p1 + geom_smooth(mapping = aes(x = min_3_all), linetype = "dashed") 
# p2

#######    #######    #######    #######    #######    #######    #######    #######    #######    #######    
    dsfo_std <- dsfo_tem2 %>%
              dplyr::group_by(common_name, alpha4, year, hatch_doy, stn_id) %>%
              dplyr::summarize(mean_fledge = mean(young_fled_atleast, na.rm=T), mean_chicks = mean(young_host_atleast, na.rm=T),
                        min_3_inc = mean(min_3_inc, na.rm=T), max_3_inc = mean(max_3_inc, na.rm=T), 
                        min_3_nes = mean(min_3_nes, na.rm=T), max_3_nes = mean(max_3_nes, na.rm=T),
                        min_3_all = mean(min_3_all, na.rm=T), max_3_all = mean(max_3_all, na.rm=T),
                        s_min_3_inc = mean(s_min_3_inc, na.rm=T), s_max_3_inc = mean(s_max_3_inc, na.rm=T), 
                        s_min_3_nes = mean(s_min_3_nes, na.rm=T), s_max_3_nes = mean(s_max_3_nes, na.rm=T), 
                        hatch_doy = mean(hatch_doy, na.rm=T), year=mean(year, na.rm=T), 
                        c_lat = mean(c_lat, na.rm=T), c_long = mean(c_long, na.rm=T)) %>%
              distinct(alpha4, year, hatch_doy, stn_id, mean_fledge, mean_chicks, min_3_inc, max_3_inc, min_3_nes, max_3_nes, min_3_all, max_3_all, s_min_3_inc, s_max_3_inc, s_min_3_nes, s_max_3_nes, c_lat, c_long)

#######    #######    #######    #######    #######    #######    #######    #######    #######    #######     
#metrics for calculating relative fitness with chick estimates
    
    d_temp2 <- dsfo_std %>%  
      dplyr::group_by(common_name) %>%
      dplyr::summarise(mean_fitness = mean(mean_fledge, na.rm = TRUE))
    
    d_temp2b <- dsfo_std %>%
      filter(mean_fledge > 0) %>%
      dplyr::group_by(common_name) %>%
      dplyr::summarise(mean_fitness_hatched = mean(mean_fledge, na.rm = TRUE))
    
# set up a variable for if any nestlings fledged
dsfo_tem$any_fled <- ifelse(dsfo_tem$young_fled_atleast > 0, 1, 0)

# set up list of species
sp_list <- unique(dsfo_tem$alpha4)


## put grid identity back into the breeding records
  stn_grids <- st_drop_geometry(sd4)[, 1:2]
  dsfo_std <- plyr::join(dsfo_std, stn_grids, "stn_id", "left", "first")

```

```{r ece-spp, echo = FALSE, message = FALSE, warning = FALSE}
# We want a list of the coldest and hottest 3 day periods normally experienced by each species
# We will use three thresholds, so I'm saving the 5th, 10th, and 15th percentile for each species

sp_ece <- data.frame(common_name = unique(dsfo_tem$common_name),
                     low5 = NA, low10 = NA, low20 = NA, high80 = NA, high90 = NA, high95 = NA)

for(i in 1:nrow(sp_ece)){
  tsp <- subset(dsfo_tem, dsfo_tem$common_name == sp_ece$common_name[i])
  sp_ece[i, 2:4] <- quantile(tsp$min_3_all, c(.05, 0.1, 0.2))
  sp_ece[i, 5:7] <- quantile(tsp$max_3_all, c(0.8, 0.9, .95))
}

sp_ece2 <- sp_ece %>%
  pivot_longer(cols = low5:high95, names_to = "quantile")



segments <- data.frame(x = colMeans(sp_ece[, 2:7]),
                       xend = colMeans(sp_ece[, 2:7]),
                       y = rep(0, 6), yend = c(0.14, 0.14, 0.14, 0.21, 0.21, 0.21))
txt_labs <- data.frame(x = colMeans(sp_ece[, 2:7]),
                       y = c(0.14, 0.14, 0.14, 0.21, 0.21, 0.21) + 0.02,
                       labs = c("Average 5th percentile (13.9 C)",
                                "Average 10th percentile (15.5 C)",
                                "Average 20th percentile (17.4 C)",
                                "Average 80th percentile (32.1 C)",
                                "Average 90th percentile (33.6 C)",
                                "Average 95th percentile (34.8 C)"))

grad_col <- colorspace::diverge_hsv(n = 7)
ece_dist <- ggplot(sp_ece2, mapping = aes(x = value, color = quantile, fill = quantile)) + 
  geom_density(alpha = 0.7, bw = 1.5, color = "transparent") +
  theme_bw() + 
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
        axis.text = element_text(size = 12), axis.title = element_text(size = 14)) +
  scale_fill_manual(values = c(grad_col[5], grad_col[6], grad_col[7],
                               grad_col[2], grad_col[3], grad_col[1])) +
  xlim(c(4, 46)) + ylim(c(0, 0.45)) +
  guides(fill = "none") +
  xlab("Three day temperature (degrees C)") +
  ylab("Density across 24 specise") +
  geom_segment(data = segments, mapping = aes(x = x, y = y, xend = xend, yend = yend),
               color = "black", lineend = "round", inherit.aes = FALSE) +
  geom_point(data = segments, mapping = aes(x = x, y = yend),
             inherit.aes = FALSE, color = "black", size = 1.5) +
  ggtitle("Distribution of 3-day temperature extremes for 24 species") +
  geom_text(data = txt_labs, mapping = aes(x = x, y = y, label = labs),
            inherit.aes = FALSE, angle = 45, hjust = 0)
  
saveRDS(ece_dist, here::here("4_output_figures", "ece_dist.rds"))

```

```{r check_stns, message = FALSE, warning = FALSE}

#This is just checking how many unique stations are recorded for each species relative to nest records. Not necessary for output.

# stn_counts <- data.frame(sp_list = sp_list,
#                          tot_nests = NA, tot_stns = NA, tot_ratio = NA, tot_stnyrs = NA, tot_stny_ratio = NA, stn_2 = NA,
#                          prov_nests = NA, prov_stns = NA, prov_ratio = NA, prov_stnyrs = NA, prov_stny_ratio = NA, stny_2 = NA)
# 
# dstn <- dsfo_std
# dstn$stn_yr <- paste0(dstn$stn_id, dstn$year)
# 
# for(i in 1:nrow(stn_counts)){
#   tem_dat3 <- subset(dstn, dstn$alpha4 == sp_list[i] & dstn$min_3_all < 999 & dstn$max_3_all > 10)
#   tem_dat4 <- subset(dstn, dstn$alpha4 == sp_list[i] & dstn$mean_chicks > 0
#                        & dstn$min_3_all < 999 & dstn$max_3_all > 10)
#   
#   u_stn <- data.frame(stn_id = unique(tem_dat3$stn_id), count = NA)
#   u_stny <- data.frame(stn_yr = unique(tem_dat3$stn_yr), count = NA)
#   for(j in 1:nrow(u_stn)){u_stn$count[j] <- nrow(subset(tem_dat3, tem_dat3$stn_id == u_stn$stn_id[j]))}
#   for(j in 1:nrow(u_stny)){u_stny$count[j] <- nrow(subset(tem_dat3, tem_dat3$stn_yr == u_stny$stn_yr[j]))}
#   
# 
#   stn_counts$tot_nests[i] <- nrow(tem_dat3)
#   stn_counts$tot_stns[i] <- length(unique(tem_dat3$stn_id))
#   stn_counts$tot_stnyrs[i] <- length(unique(tem_dat3$stn_yr))
#   stn_counts$prov_nests[i] <- nrow(tem_dat4)
#   stn_counts$prov_stns[i] <- length(unique(tem_dat4$stn_id))
#   stn_counts$prov_stnyrs[i] <- length(unique(tem_dat4$stn_yr))
#   stn_counts$stn_2[i] <- nrow(subset(u_stn, u_stn$count < 3))
#   stn_counts$stny_2[i] <- nrow(subset(u_stny, u_stny$count < 3))
#   
#   
# }
# 
# stn_counts$tot_ratio <- round(stn_counts$tot_nests / stn_counts$tot_stns, 1)
# stn_counts$tot_stny_ratio <- round(stn_counts$tot_nests / stn_counts$tot_stnyrs, 1)
# stn_counts$prov_ratio <- round(stn_counts$prov_nests / stn_counts$prov_stns, 1)
# stn_counts$prov_stny_ratio <- round(stn_counts$prov_nests / stn_counts$prov_stnyrs, 1)
# 
# stn_counts$two_stn_pct <- round(stn_counts$stn_2 / stn_counts$tot_stns, 2)
# stn_counts$two_stny_pct <- round(stn_counts$stny_2 / stn_counts$tot_stnyrs, 2)

```

```{r sp-gams, echo = FALSE, message = FALSE, warning = FALSE}
# fit hurdle gams for each species

# set up list of species
sp_list <- unique(dsfo_tem$alpha4)

# set up objects to store saved models from loop
bin_fled_inc <- list(rep(NA, length(sp_list)))
bin_fled_nest <- list(rep(NA, length(sp_list)))

num_fled_inc <- list(rep(NA, length(sp_list)))
num_fled_nest <- list(rep(NA, length(sp_list)))
#num_fled_all <- list(rep(NA, length(sp_list)))
#any_fled_ms <- list(rep(NA, length(sp_list)))
#any_fled_nest <- list(rep(NA, length(sp_list)))

dsfo_std$stn_id2 <- as.factor(dsfo_std$stn_id)
dsfo_std$grid_id2 <- as.factor(dsfo_std$id)
dsfo_std$grid_id3 <- as.factor(paste0(dsfo_std$grid_id, dsfo_std$year))

# loop through and fit models for each species
for(i in 1:length(sp_list)){
#######    #######    #######    #######    #######    #######    #######    #######    #######    #######  
    # subset to species. remove records with missing/wrong temperature
    tem_dat3 <- subset(dsfo_std, dsfo_std$alpha4 == sp_list[i] & dsfo_std$min_3_all < 999 & dsfo_std$max_3_all > 10)
    tem_dat3_stn_ratio <- nrow(tem_dat3) / length(unique(tem_dat3$grid_id3))
    
      #set basis dimensions of spatial autocorrelation based on 75% the number of unique sites
      spatial_k <- floor(length(levels(as.factor(tem_dat3$stn_id))) * 0.5)
    
      # fit model for number of young fledged with enough for random effect of station. not used
           # if(tem_dat3_stn_ratio > 1.8){
           #   binc <- gam(mean_fledge ~ s(s_min_3_inc) + s(s_max_3_inc) + s(hatch_doy) + s(year) +
           #        s(c_long, c_lat, k=spatial_k) + s(grid_id3, bs = 're'),  data = tem_dat3)
           # }
      
      # fit model for number of young fledged without enough for random effect of station
           #if(tem_dat3_stn_ratio < 1.8){
             binc <- gam(mean_fledge ~ s(s_min_3_inc) + s(s_max_3_inc) + s(hatch_doy) + s(year) +
                  s(c_long, c_lat, k=spatial_k),  data = tem_dat3)
           #}


     # save output
     num_fled_inc[[i]] <- binc
     
#######    #######    #######    #######    #######    #######    #######    #######    #######    #######    
    # subset to only nests that hatched and weather during nestling period
    tem_dat4 <- subset(dsfo_std, dsfo_std$alpha4 == sp_list[i] & dsfo_std$mean_chicks > 0 
                       & dsfo_std$min_3_all < 999 & dsfo_std$max_3_all > 10)
    tem_dat4_stn_ratio <- nrow(tem_dat4) / length(unique(tem_dat4$grid_id3))
    
      # fit model for number fledged for records with enough observations for random effect of station. not used
           # if(tem_dat4_stn_ratio > 1.8){
           #   mnest <- gam(mean_fledge ~ s(s_min_3_nes) + s(s_max_3_nes) + s(hatch_doy) + s(year) +
           #          s(c_long, c_lat, k=spatial_k) + s(grid_id3, bs = 're'), data = tem_dat4)
           # }
    
      # fit model for number fledged for records without enough observations for random effect of station
           #if(tem_dat4_stn_ratio < 1.8){
             mnest <- gam(mean_fledge ~ s(s_min_3_nes) + s(s_max_3_nes) + s(hatch_doy) + s(year) +
                    s(c_long, c_lat, k=spatial_k), data = tem_dat4)
           #}
      
    
    # save output
    num_fled_nest[[i]] <- mnest
      
    print(sp_list[i])
    print(Sys.time())
    
}

# saveRDS(num_fled_inc, here::here("2_modified_data", "num_fled_inc.rds"))
# saveRDS(num_fled_nest, here::here("2_modified_data", "num_fled_nest.rds"))

num_fled_inc <- readRDS(here::here("2_modified_data/num_fled_inc.rds"))
num_fled_nest <- readRDS(here::here("2_modified_data/num_fled_nest.rds"))

```

```{r spgam-checks, echo = FALSE, warning = FALSE, message = FALSE}
# Check models for incubation 

   basis_table_inc <- data.frame(alpha4 = sp_list,
                              min_k = NA, min_edf = NA, min_k_idx = NA, min_p = NA,
                              max_k = NA, max_edf = NA, max_k_idx = NA, max_p = NA,
                              doy_k = NA, doy_edf = NA, doy_k_idx = NA, doy_p = NA,
                              spa_k = NA, spa_edf = NA, spa_k_idx = NA, spa_p = NA
                              )
    
    basis_check <- function(b, k.sample = 500, k.rep = 200) {
         mgcv:::k.check(b, subsample = k.sample, n.rep = k.rep)
    }
    
    for(i in 1:length(sp_list)){
      out <- basis_check(num_fled_inc[[i]])
      
      basis_table_inc$min_k[i]      <- out[1]
      basis_table_inc$min_edf[i]    <- out[6]
      basis_table_inc$min_k_idx[i]  <- out[11]
      basis_table_inc$min_p[i]      <- out[16]
      basis_table_inc$max_k[i]      <- out[2]
      basis_table_inc$max_edf[i]    <- out[7]
      basis_table_inc$max_k_idx[i]  <- out[12]
      basis_table_inc$max_p[i]      <- out[17]
      basis_table_inc$doy_k[i]      <- out[3]
      basis_table_inc$doy_edf[i]    <- out[8]
      basis_table_inc$doy_k_idx[i]  <- out[13]
      basis_table_inc$doy_p[i]      <- out[18]
      basis_table_inc$spa_k[i]       <- out[5]
      basis_table_inc$spa_edf[i]     <- out[10]
      basis_table_inc$spa_k_idx[i]   <- out[15]
      basis_table_inc$spa_p[i]       <- out[20]
    }
    
    saveRDS(basis_table_inc, here::here("6_saved_data_objects", "basis_table_inc.rds"))
    
# check models for provisioning
    
    basis_table_nest <- data.frame(alpha4 = sp_list,
                          min_k = NA, min_edf = NA, min_k_idx = NA, min_p = NA,
                          max_k = NA, max_edf = NA, max_k_idx = NA, max_p = NA,
                          doy_k = NA, doy_edf = NA, doy_k_idx = NA, doy_p = NA,
                          spa_k = NA, spa_edf = NA, spa_k_idx = NA, spa_p = NA
                          )

      basis_check <- function(b, k.sample = 500, k.rep = 200) {
           mgcv:::k.check(b, subsample = k.sample, n.rep = k.rep)
      }
      
      for(i in 1:length(sp_list)){
        out <- basis_check(num_fled_nest[[i]])
        
        basis_table_nest$min_k[i]      <- out[1]
        basis_table_nest$min_edf[i]    <- out[6]
        basis_table_nest$min_k_idx[i]  <- out[11]
        basis_table_nest$min_p[i]      <- out[16]
        basis_table_nest$max_k[i]      <- out[2]
        basis_table_nest$max_edf[i]    <- out[7]
        basis_table_nest$max_k_idx[i]  <- out[12]
        basis_table_nest$max_p[i]      <- out[17]
        basis_table_nest$doy_k[i]      <- out[3]
        basis_table_nest$doy_edf[i]    <- out[8]
        basis_table_nest$doy_k_idx[i]  <- out[13]
        basis_table_nest$doy_p[i]      <- out[18]
        basis_table_nest$spa_k[i]       <- out[5]
        basis_table_nest$spa_edf[i]     <- out[10]
        basis_table_nest$spa_k_idx[i]   <- out[15]
        basis_table_nest$spa_p[i]       <- out[20]
      }
      
      saveRDS(basis_table_nest, here::here("6_saved_data_objects", "basis_table_nest.rds"))


```

```{r sp-gamplots, echo = FALSE, warning = FALSE, message = FALSE}
# code to make plots from the gams for each species

  # basic plots of all effects from every model, not included
      # for(i in 1:length(sp_list)){
      #     print(sp_list[i])
      #     plot(bin_fled_nest[[i]], pages=1, main=sp_list[i] )
      # }
      # 
      # for(i in 1:length(sp_list)){
      #   print(sp_list[i])
      #   plot(num_fled_nest[[i]], pages=1, main=sp_list[i] )
      # }

# Create a table with point estimates from each model
  # get point estimates out for 2sd snaps and waves
  sens_table <- data.frame(alpha4 = sp_list,
                           inc_cold_mu = NA, inc_cold_lo = NA, inc_cold_hi = NA,
                           inc_hot_mu = NA, inc_hot_lo = NA, inc_hot_hi = NA,
                           nes_cold_mu = NA, nes_cold_lo = NA, nes_cold_hi = NA,
                           nes_hot_mu = NA, nes_hot_lo = NA, nes_hot_hi = NA
                           )

  
  
  
  ##EDITED to account for new model structure
    for(i in 1:nrow(sens_table)){
    # subsets of data for each species
    # 2sd snap during incubation
      y1 <- get_gam_predictions2(num_fled_inc[[i]], s_min_3_inc, series_jump = 0.25, exclude_terms = "s(hatch_doy)")
      y1b <- subset(y1, y1$s_min_3_inc == -2)[1, ]
      sens_table$inc_cold_mu[i] <- y1b$mean_fledge[1]
      sens_table$inc_cold_lo[i] <- y1b$CI_lower[1]
      sens_table$inc_cold_hi[i] <- y1b$CI_upper[1]
    # 2sd wave during incubation
      y2 <- get_gam_predictions2(num_fled_inc[[i]], s_max_3_inc, series_jump = 0.25)
      y2b <- subset(y2, y2$s_max_3_inc == 2)[1, ]
      sens_table$inc_hot_mu[i] <- y2b$mean_fledge[1]
      sens_table$inc_hot_lo[i] <- y2b$CI_lower[1]
      sens_table$inc_hot_hi[i] <- y2b$CI_upper[1]
    # 2sd snap during provisioning
      y3 <- get_gam_predictions2(num_fled_nest[[i]], s_min_3_nes, series_jump = 0.25)
      y3b <- subset(y3, y3$s_min_3_nes == -2)[1, ]
      sens_table$nes_cold_mu[i] <- y3b$mean_fledge[1]
      sens_table$nes_cold_lo[i] <- y3b$CI_lower[1]
      sens_table$nes_cold_hi[i] <- y3b$CI_upper[1]
    # 2sd wave during incubation
      y4 <- get_gam_predictions2(num_fled_nest[[i]], s_max_3_nes, series_jump = 0.25)
      y4b <- subset(y4, y4$s_max_3_nes == 2)[1, ]
      sens_table$nes_hot_mu[i] <- y4b$mean_fledge[1]
      sens_table$nes_hot_lo[i] <- y4b$CI_lower[1]
      sens_table$nes_hot_hi[i] <- y4b$CI_upper[1]
  }
  

 #sens_table <- cbind(sens_table[1], (apply(sens_table[2:13], FUN=function(x) exp(x), MARGIN=2)))
  
  common_name <- data.frame(`common_name` = c("Northern Cardinal", "House Finch", "Barn Swallow", "Black-Capped Chickadee", 
                                              "Purple Martin", "Eastern Phoebe", "Eastern Bluebird", "Tree Swallow", 
                                              "House Wren", "American Robin", "Mourning Dove", "White-Breasted Nuthatch", 
                                              "Prothonotary Warbler", "Tufted Titmouse", "Carolina Chickadee", "Mountain Chickadee", 
                                              "Chestnut-Backed Chickadee", "Mountain Bluebird", "Western Bluebird", "Violet-Green Swallow", 
                                              "Bewick's Wren", "Oak Tit", "Brown-Headed Nuthatch", "Black-Crested Titmouse"), 
                            alpha4 = c("NOCA", "HOFI", "BARS", "BCCH", 
                                       "PUMA", "EAPH", "EABL", "TRES", 
                                       "HOWR", "AMRO", "MODO", "WBNU", 
                                       "PROW", "TUTI", "CACH", "MOCH", 
                                       "CBCH", "MOBL", "WEBL", "VGSW", 
                                       "BEWR", "OATI", "BHNU", "BCTI"))
  
  sens_table <- merge(common_name, sens_table, id=c("alpha4"))
  
  sens_table <- merge(d_temp2, sens_table, id=c("common_name"))
  
  sens_table <- merge(d_temp2b, sens_table, id=c("common_name"))
  
  sens_table <- sens_table %>%
                  dplyr::mutate(across(inc_cold_mu : inc_hot_hi, ~ .x / mean_fitness)) %>%
                  dplyr::mutate(across(nes_cold_mu : nes_hot_hi, ~ .x / mean_fitness_hatched))
  
  sens_table <- sens_table[,-(1:3)]
  
  saveRDS(sens_table, here::here("2_modified_data", "sens_table.rds"))



```

```{r sp-sumplot, message = FALSE, warning = FALSE, message = FALSE}
# making a summary plot of point estimates for each species from models above
      ord <- dsfo_tem2 %>%
        dplyr::group_by(common_name) %>%
        dplyr::summarise(mean_min = mean(min_3_all))
      ord <- ord[order(ord$mean_min), ]
      
    # add in foraging style groups
        style <- data.frame(common_name = unique(dsfo_tem2$common_name),
                            forage_style = c("4glean", "5seed", "1aerial", "4glean", 
                                             "1aerial", "2hawk", "3sally", "1aerial",
                                             "4glean", "4glean", "5seed", "4glean",
                                             "4glean", "4glean", "4glean", "4glean",
                                             "3sally", "3sally", "1aerial", "4glean",
                                             "4glean", "4glean", "4glean", "4glean"),
                            style2 = c(11, 1, 24, 7, 23, 20, 19, 21, 14, 8, 2, 6,
                                       12, 9, 5, 4, 17, 18, 22, 16, 3, 15, 10, 13))
        ord <- plyr::join(ord, style, "common_name")
        ord <- ord[order(ord$forage_style), ]
    
      ddd <-dsfo_tem2[, c("common_name", "min_3_all", "max_3_all")]
      ddd2 <- ddd%>%
        pivot_longer(cols = starts_with("m"), values_to = "temperature", names_to = "category")
    
      ddd2 <- plyr::join(ddd2, ord, "common_name")
      ddd2$cn <- fct_reorder(ddd2$common_name, ddd2$style2, min)
    
      ddd3 <- ddd2 %>%
        dplyr::group_by(common_name, category) %>%
        dplyr::summarise(mean = mean(temperature), sd = sd(temperature))
      ddd3$temp2sd <- NA
      for(i in 1:nrow(ddd3)){
        if(ddd3$category[i] == "max_3_all"){ddd3$temp2sd[i] <- ddd3$mean[i] + 2*ddd3$sd[i]}
        if(ddd3$category[i] == "min_3_all"){ddd3$temp2sd[i] <- ddd3$mean[i] - 2*ddd3$sd[i]}
      }
      ddd3 <- plyr::join(ddd3, ord, "common_name")
      ddd3$cn <- fct_reorder(ddd3$common_name, ddd3$style2, min)
      dodger1 <- data.frame(category = c("max_3_all", "min_3_all"),
                            dodgy = c(-.2, .2))
      ddd3 <- plyr::join(ddd3, dodger1, "category")
      

    
    
      pa <- ggplot(data = ddd2, mapping = aes(x = temperature, y = cn, fill = category)) +
        geom_boxplot(outlier.shape = NA, alpha = 0.7) +
        guides(fill = "none", color = "none") +
        theme_bw() +
        theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 12), axis.title = element_text(size = 14),
              plot.title = element_text(hjust = 0.5)) +
        scale_fill_manual(values = c("coral3", "slateblue")) +
        ylab("") +
        xlab("Degrees C") +
        coord_cartesian(xlim = c(3, 43)) +
        annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "A") +
        ggtitle("3-day temperature extremes \n in full nesting cycle") +
        geom_point(data = ddd3, mapping = aes(x = temp2sd, y = cn, color = category), shape = 4,
                   position = position_nudge(y = ddd3$dodgy)) +
        scale_color_manual(values = c("coral3", "slateblue"))
      
    # rearrange sens table
      sens_table2 <- data.frame(
        alpha4 = rep(sens_table$alpha4, 2),
        inc_mu = c(sens_table$inc_cold_mu, sens_table$inc_hot_mu),
        inc_lo = c(sens_table$inc_cold_lo, sens_table$inc_hot_lo),
        inc_hi = c(sens_table$inc_cold_hi, sens_table$inc_hot_hi),
        nes_mu = c(sens_table$nes_cold_mu, sens_table$nes_hot_mu),
        nes_lo = c(sens_table$nes_cold_lo, sens_table$nes_hot_lo),
        nes_hi = c(sens_table$nes_cold_hi, sens_table$nes_hot_hi),
        cat = c(rep("cold", nrow(sens_table)), rep("hot", nrow(sens_table)))
      )
      
      sens_table2$inc_sig <- "no"
      sens_table2$nes_sig <- "no"
      for(i in 1:nrow(sens_table2)){
        if(sens_table2$inc_hi[i] < 1){
          sens_table2$inc_sig[i] <- "yes"
        }
        if(sens_table2$inc_lo[i] > 1){
          sens_table2$inc_sig[i] <- "yes"
        }
        
        if(sens_table2$nes_hi[i] < 1){
          sens_table2$nes_sig[i] <- "yes"
        }
        if(sens_table2$nes_lo[i] > 1){
          sens_table2$nes_sig[i] <- "yes"
        }
      }
      
      dodger <- data.frame(cat = c("cold", "hot"),
                           dodger = c(0.1, -0.1))
      sens_table2 <- plyr::join(sens_table2, dodger, "cat")
      sens_table2 <- plyr::join(sens_table2, dsfo_tem[, c("alpha4", "common_name")], "alpha4", "left", "first")
      sens_table2 <- plyr::join(sens_table2, ord, "common_name")
      sens_table2$cn <- fct_reorder(sens_table2$common_name, sens_table2$style2, min)
      
      pb <- ggplot(data = sens_table2, mapping = aes(x = inc_mu, y = cn, color = cat, shape = inc_sig)) +
        geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
        geom_segment(mapping = aes(x = inc_lo, xend = inc_hi, y = cn, yend = cn),
                     position = position_nudge(y = sens_table2$dodger)) +
        geom_point(position = position_nudge(y = sens_table2$dodger), size = 2.5, fill = "white") +
        scale_color_manual(values = c("slateblue", "coral3")) +
        theme_bw() +
        theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
        coord_cartesian(xlim = c(0.6, 1.4)) +
        xlab("Relative fitness") +
        scale_shape_manual(values = c(21, 16)) +
        guides(shape = "none", color = "none") +
        ylab("") +
        annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B") +
        ggtitle("Incubation sensitivity to \n 2 SD cold or heat")
      
      pc <- ggplot(data = sens_table2, mapping = aes(x = nes_mu, y = cn, color = cat, shape = nes_sig)) +
        geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
        geom_segment(mapping = aes(x = nes_lo, xend = nes_hi, y = cn, yend = cn),
                     position = position_nudge(y = sens_table2$dodger)) +
        geom_point(position = position_nudge(y = sens_table2$dodger), size = 2.5, fill = "white") +
        scale_color_manual(values = c("slateblue", "coral3")) +
        theme_bw() +
        theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
        xlab("Relative fitness") +
        coord_cartesian(xlim = c(0.6, 1.4)) +
        scale_shape_manual(values = c(21, 16)) +
        guides(shape = "none", color = "none") +
        ylab("") +
        annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "C") +
        ggtitle("Provisioning sensitivity to \n 2 SD cold or heat")
      
    p_sens <- ggarrange(pa, pb, pc, nrow = 1, widths = c(1.8, 1, 1))
    saveRDS(p_sens, file = here::here("4_output_figures", "p_sens.rds")) 
  
    # saving to png to add some labeling in inkscape
    ggsave(plot = p_sens, filename = "sensitivity_plot.svg", device = "svg", height = 7.2, width = 10.3, units = "in")

```

```{r spgam-plots, warning = FALSE, message = FALSE, echo = FALSE}
# making plots from every model. Not included and no need to run
# pdf(file = "plots.pdf", width = 8, height = 4)
#   par(mfrow = c(1, 2))
# for(i in 1:length(sp_list)){
#   
#   # subset to species. remove records with missing/wrong temperature
#     tem_dat <- subset(dsfo_tem2, dsfo_tem2$alpha4 == sp_list[i] & dsfo_tem2$min_3_all < 999 & dsfo_tem2$max_3_all > -20)
#     
#   # subset to only nests that hatched and weather during nestling period
#     tem_dat2 <- subset(dsfo_tem2, dsfo_tem2$alpha4 == sp_list[i] & 
#                           dsfo_tem2$min_3_nes < 999 & dsfo_tem2$max_3_nes > 10 &
#                           dsfo_tem2$young_host_atleast > 0)
#     
#   toofar <- 0.05  
# 
#   print(sp_list[i])
#   titer <- sp_list[i]
#   vis.gam(num_fled_inc[[i]], plot.type = "contour", too.far = toofar, 
#         xlab = "Lowest 3-day maximum temperature", ylab = "Highest 3-day maximum temperature",
#         main = paste(titer, "Incubation", sep = " "),
#         #xlim = c(-3.5, 3.5), ylim = c(-3.5, 3.5),
#         axes = FALSE) 
#   #polygon(x = c(0, 100, 100, 0), y = c(0, 100, 0, 0), col = "gray85", border = "gray40")
#   axis(side = 1, at = seq(-10, 10, 1))
#   axis(side = 2, at = seq(-10, 10, 1)) 
#   axis(side = 3, at = c(-50, 50))
#   axis(side = 4, at = c(-50, 50))
#   #points(tem_dat$s_min_3_inc, tem_dat$s_max_3_inc, pch = 16, cex = 0.3)
#   # vis.gam(any_fled_ms[[i]], plot.type = "contour", too.far = toofar, 
#   #       xlab = "Lowest 3-day maximum temperature", ylab = "Highest 3-day maximum temperature",
#   #       main = sp_list[i])
#   # #polygon(x = c(0, 100, 100, 0), y = c(0, 100, 0, 0), col = "gray85", border = "gray40")
#   # axis(side = 1, at = seq(-10, 40, 10))
#   # axis(side = 2, at = seq(-10, 50, 10)) 
#   # axis(side = 3, at = c(-50, 100))
#   # axis(side = 4, at = c(-50, 100))
#   # points(tem_dat$min_3_all, tem_dat$max_3_all, pch = 16, cex = 0.3)
#   
#   vis.gam(num_fled_nest[[i]], plot.type = "contour", too.far = toofar, 
#         xlab = "Lowest 3-day maximum temperature", ylab = "Highest 3-day maximum temperature",
#         #xlim = c(-3.5, 3.5), ylim = c(-3.5, 3.5),
#         main = paste(titer, "Provisioning", sep = " "))
#   #polygon(x = c(0, 100, 100, 0), y = c(0, 100, 0, 0), col = "gray85", border = "gray40")
#   axis(side = 1, at = seq(-10, 10, 1))
#   axis(side = 2, at = seq(-10, 10, 1)) 
#   axis(side = 3, at = c(-50, 50))
#   axis(side = 4, at = c(-50, 50))
#   
#   #points(tem_dat2$s_min_3_nes, tem_dat2$s_max_3_nes, pch = 16, cex = 0.3)
#   # vis.gam(any_fled_nest[[i]], plot.type = "contour", too.far = toofar, 
#   #       xlab = "Lowest 3-day maximum temperature", ylab = "Highest 3-day maximum temperature",
#   #       main = "Nestling stage", xlim = c(-2, 37), ylim = c(7, 42))
#   # polygon(x = c(0, 100, 100, 0), y = c(0, 100, 0, 0), col = "gray85", border = "gray40")
#   # axis(side = 1, at = seq(-10, 40, 10))
#   # axis(side = 2, at = seq(-10, 50, 10)) 
#   # axis(side = 3, at = c(-50, 100))
#   # axis(side = 4, at = c(-50, 100))
#   # points(tem_dat2$min_3_nes, tem_dat2$max_3_nes, pch = 16, cex = 0.3)
#   
#   
# }
# dev.off()

```

```{r concept-plot}
# This plot isn't included in the manuscript but illustrates the general interpretation of heat/cold variation

#6.5x6.5 inches
plot(x = 1, y = 1, type = "n", xlim = c(5, 35), ylim = c(7, 36), axes = FALSE, cex.lab = 1.2,
     xlab = "Lowest 3-day maximum temperature", ylab = "Highest 3-day maximum temperature", xaxs = "i", yaxs = "i")
polygon(x = c(0, 100, 100, 0), y = c(0, 100, 0, 0), col = "gray85", border = "gray40")
polygon(x = c(-20, 18.5, 18.5, -20), y = c(18.5, 18.5, 26, 26), col = "lightblue", border = "gray40")
polygon(x = c(-20, 18.5, 18.5, -20), y = c(0, 0, 18.5, 18.5), col = alpha("blue3", 0.5), border = "gray40")
polygon(x = c(26, 50, 50, 26), y = c(26, 26, 50, 50), col = alpha("tomato", 0.8), border = "gray40") 
polygon(x = c(-20, 18.5, 18.5, -20), y = c(26, 26, 50, 50), col = alpha("orchid", 0.5), border = "gray40")
polygon(x = c(18.5, 26, 26, 18.5), y = c(26, 26, 50, 50), col = alpha("darkorange", 0.6), border = "gray40")
  axis(side = 1, at = seq(-10, 40, 10))
  axis(side = 2, at = seq(-10, 50, 10)) 
  axis(side = 3, at = c(-50, 100))
  axis(side = 4, at = c(-50, 100))
  text(x = 12.25, y = 22, "Cold snap +\n consistent warm") 
  text(x = 12.25, y = 12, "Cold snap +\n consistent cold")
  text(x = 30.5, y = 30.5, "Heat wave +\n consistent hot")
  text(x = 12.25, y = 30.5, "Cold snap +\n Heat wave")
  text(x = 26, y = 15.5, "No 3-day extremes")
  text(x = 22.25, y = 30.5, "Heat wave +\n consistent warm")
 # text(x = 27, y = 15, "Not possible")
  #plotrix::corner.label(x = -1, y = 1, label = "A")
```

```{r sp-maps, echo = FALSE, message = FALSE, warning = FALSE}
# getting some maps ready for species specific plots

# Summarize by group of hexagon id and species  
      # Can be modified to summarize by plot group or addition of by year for faceting
        n_summary <- n_in_g %>%
          dplyr::group_by(id, species_code) %>%
          dplyr::summarize(n = n(), fled = mean(young_fled_atleast, na.rm = TRUE), 
                          clutch = mean(clutch_host_atleast, na.rm = TRUE),
                          lay = mean(lay_doy, na.rm = TRUE),
                          nfled = sum(young_fled_atleast > 0, na.rm = TRUE),
                          pct_fled = sum(young_fled_atleast > 0, na.rm = TRUE) / n())
        n_summary$join_to_record <- paste(n_summary$species_code, n_summary$id, sep = "_")
        #st_geometry(n_summary) <- NULL
        
      # Join grid level summary to each record
        n_in_g$join_to_record <- paste(n_in_g$species_code, n_in_g$id, sep = "_")
        n_in_g <- left_join(n_in_g, st_drop_geometry(n_summary), by = "join_to_record")
        n_in_g$rel_lay_doy <- n_in_g$lay_doy - n_in_g$lay.y
        n_in_g$rel_fled <- n_in_g$young_fled_atleast / n_in_g$fled
        n_in_g$rel_clutch <- n_in_g$clutch_host_atleast / n_in_g$clutch
        
      # Summarize again to relative lay dates by year
        n_summary2 <- n_in_g %>%
          dplyr::group_by(id.x, alpha4, year) %>%
          dplyr::summarize(n = n(), fled = mean(rel_fled, na.rm = TRUE), 
                           clutch = mean(rel_clutch, na.rm = TRUE),
                           lay = mean(rel_lay_doy, na.rm = TRUE),
                           nfled = sum(young_fled_atleast > 0, na.rm = TRUE))
        n_summary2 <- subset(n_summary2, n_summary2$nfled > 10)
```

```{r puma-only, message = FALSE, warning = FALSE, echo = FALSE}
# make a map of breeding timing

    # subset the summarized data to one species or one plot group
        s_sub <- subset(n_summary, n_summary$species_code == "purmar" | n_summary$species_code == "purmar1")
        grid_s <- st_join(grid, s_sub, join = st_intersects)
        grid_s <- subset(grid_s, grid_s$n > 10)
      
      # Make a figure for lay date, clutch size, fledged number, and fledge y/n for that species
          p_lay_puma <- p_base + geom_sf(data = grid_s, mapping = aes(fill = lay)) + ggtitle("Purple Martin") +
            coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], 3300000)) +
            scale_fill_viridis(alpha = 0.8, guide = guide_colorbar(title = "Laying day \n of year")) +
            annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "A", fontface = 2)
          
  
        ggsave(here::here("4_output_figures", "puma_map.svg"), plot = p_lay_puma, device = "svg",
               units = "in", width = 5.9, height = 3.4)
            

          
# split by latitude          
  ## Analyses with individual species
          one_sp <- subset(dsfo_std, dsfo_std$alpha4 == "PUMA")

     # create a factor level with equal samples split by longitude
          splits <- 5 # how many bands to make
          one_sp <- one_sp %>%
            arrange(c_lat) %>%
            mutate(lat_band = ntile(c_lat, splits))
          one_sp$lat_band <- as.factor(one_sp$lat_band)
      # recalculate sd of temperature for each band
          one_sp$s_min_3_inc2 <- transform(one_sp, s_min_3_inc2 = ave(min_3_inc, lat_band, FUN = scale))$s_min_3_inc2
          one_sp$s_max_3_inc2 <- transform(one_sp, s_max_3_inc2 = ave(max_3_inc, lat_band, FUN = scale))$s_max_3_inc2
          one_sp$s_min_3_nes2 <- transform(one_sp, s_min_3_nes2 = ave(min_3_nes, lat_band, FUN = scale))$s_min_3_nes2
          one_sp$s_max_3_nes2 <- transform(one_sp, s_max_3_nes2 = ave(max_3_nes, lat_band, FUN = scale))$s_max_3_nes2
          
          
          one_spn <- subset(one_sp, one_sp$mean_chicks > 0)
          one_sp2 <- one_sp %>%
            pivot_longer(cols = c("min_3_all", "max_3_all"), values_to = "temperature", names_to = "category")

    # recalculate relative fitness for each band
            rel_one <- one_sp %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness2 = mean(mean_fledge))
          
          one_sp <- plyr::join(one_sp, rel_one, "lat_band", "left", "first")
          one_sp$w_fitness2 <- one_sp$mean_fledge / one_sp$mean_fitness2
          
          rel_one2 <- one_spn %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness_hatched2 = mean(mean_fledge))
          
          one_spn <- plyr::join(one_spn, rel_one2, "lat_band", "left", "first")
          one_spn$w_fitness_b2 <- one_spn$mean_fledge / one_spn$mean_fitness_hatched2
          
      # manipulating to get the range of latitudes in each band in degree projection    
          one_sp_o <- one_sp %>%
            st_as_sf(coords = c("c_long", "c_lat"), crs = proj_code) %>%
            st_transform(crs = crs(namer_o))
          
          one_sp_o$c_lat <- st_coordinates(one_sp_o)[, 2]
          one_sp_o$c_long <- st_coordinates(one_sp_o)[, 1]
          
          one_sp_o2 <- one_sp_o %>%
            st_drop_geometry() %>%
            arrange(c_lat) %>%
            dplyr::mutate(lat_band2 = ntile(c_lat, splits))
          one_sp_o2$lat_band2 <- as.factor(one_sp_o2$lat_band2)
          
          xx <- one_sp_o2 %>%
            dplyr::group_by(lat_band2) %>%
            dplyr::summarise(min = min(c_lat), max = max(c_lat), n = n())
          
    # make plots
          puma_p1 <- ggplot(one_sp2, mapping = aes(x = temperature, y = lat_band, fill = category)) +
            geom_boxplot(outlier.shape = NA, alpha = 0.7) +
            guides(fill = "none", color = "none") +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 12), axis.title = element_text(size = 14),
              plot.title = element_text(hjust = 0.5)) +
            scale_fill_manual(values = c("coral3", "slateblue")) +
            ylab("") +
            xlab("Degrees C") +
            coord_cartesian(xlim = c(12, 42), ylim = c(1, 5)) +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B", size = 6) +
            ggtitle("3-day temperature extremes \n in full nesting cycle") +
            ylab("Latitude band (equal samples)") +
            theme(axis.text.y = element_blank())
          
          # ggplot(one_sp, mapping = aes(x = c_long, y = max_3_nes)) +
          #   geom_smooth(method = "lm", color = "coral3", fill = "coral3") +
          #   geom_smooth(method = "lm", mapping = aes(y = min_3_nes), color = "slateblue", fill = "slateblue")
          
########################
#one_sp <- one_sp %>%
#              dplyr::group_by(year, hatch_doy, stn_id) %>%
#              summarize(mean_fledge = mean(young_fled_atleast, na.rm=T), s_min_3_nes = mean(s_min_3_nes, na.rm=T), s_max_3_nes = mean(s_max_3_nes, na.rm=T), hatch_doy = mean(hatch_doy, na.rm=T), year=mean(year, na.rm=T), c_lat = mean(c_lat, na.rm=T), c_long = mean(c_long, na.rm=T), lat_band=lat_band) %>%
#              distinct(year, hatch_doy, stn_id, mean_fledge, s_min_3_nes, s_max_3_nes, c_lat, c_long, lat_band)
########################       
          
          levs <- levels(one_sp$lat_band)
          incmods <- list(NA)
          nesmods <- list(NA)
          one_sp_table <- data.frame(inc_cold_mu = rep(NA, splits), inc_cold_lo = NA, inc_cold_hi = NA,
                                   inc_hot_mu = NA,  inc_hot_lo = NA, inc_hot_hi = NA,
                                   nes_cold_mu = NA, nes_cold_lo = NA, nes_cold_hi = NA,
                                   nes_hot_mu = NA, nes_hot_lo = NA, nes_hot_hi = NA,
                                   lat_band = seq(1, splits))
          
          one_sp$stn_id2 <- as.factor(one_sp$stn_id)
          
          for(i in 1:splits){
            tem_dat <- one_sp[one_sp$lat_band == levs[i], ]
            spatial_k <- floor(length(levels(as.factor(tem_dat$stn_id))) * 0.75)
            
            minc1 <- gam(mean_fledge ~ s(s_min_3_inc2) + s(s_max_3_inc2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k) + s(as.factor(tem_dat4$stn_id), bs = "re"), data = one_sp[one_sp$lat_band == levs[i], ])
            
          
            mnes1 <- gam(mean_fledge ~ s(s_min_3_nes2) + s(s_max_3_nes2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k) + s(as.factor(tem_dat4$stn_id), bs = "re"), data = one_spn[one_spn$lat_band == levs[i], ])
            
            incmods[[i]] <- minc1
            nesmods[[i]] <- mnes1
          }
          
            saveRDS(incmods, here::here("6_saved_data_objects", "puma_incmods.rds"))
            saveRDS(nesmods, here::here("6_saved_data_objects", "puma_nesmods.rds"))
          
          for(i in 1:nrow(one_sp_table)){
            p1 <- get_gam_predictions2(nesmods[[i]], s_min_3_nes2, series_jump = 1)
            p1b <- subset(p1, p1$s_min_3_nes2 == -2)[1, ]
            one_sp_table$nes_cold_mu[i] <- p1b$mean_fledge[1]
            one_sp_table$nes_cold_lo[i] <- p1b$CI_lower[1]
            one_sp_table$nes_cold_hi[i] <- p1b$CI_upper[1]
            
            p2 <- get_gam_predictions2(nesmods[[i]], s_max_3_nes2, series_jump = 1)
            p2b <- subset(p2, p2$s_max_3_nes2 == 2)[1, ]
            one_sp_table$nes_hot_mu[i] <- p2b$mean_fledge[1]
            one_sp_table$nes_hot_lo[i] <- p2b$CI_lower[1]
            one_sp_table$nes_hot_hi[i] <- p2b$CI_upper[1]
            
            p3 <- get_gam_predictions2(incmods[[i]], s_min_3_inc2, series_jump = 1)
            p3b <- subset(p3, p3$s_min_3_inc2 == -2)[1, ]
            one_sp_table$inc_cold_mu[i] <- p3b$mean_fledge[1]
            one_sp_table$inc_cold_lo[i] <- p3b$CI_lower[1]
            one_sp_table$inc_cold_hi[i] <- p3b$CI_upper[1]
            
            p4 <- get_gam_predictions2(incmods[[i]], s_max_3_inc2, series_jump = 1)
            p4b <- subset(p4, p4$s_max_3_inc2 == 2)[1, ]
            one_sp_table$inc_hot_mu[i] <- p4b$mean_fledge[1]
            one_sp_table$inc_hot_lo[i] <- p4b$CI_lower[1]
            one_sp_table$inc_hot_hi[i] <- p4b$CI_upper[1]
            
          }
            
          #one_sp_table <- cbind(apply(one_sp_table[1:12], FUN=function(x) exp(x), MARGIN=2), one_sp_table[13])
  
          one_sp_table <- merge(rel_one2, one_sp_table, id=c("lat_band"))
  
          one_sp_table <- merge(rel_one, one_sp_table, id=c("lat_band"))
  
          one_sp_table <- one_sp_table %>%
                  dplyr::mutate(across(inc_cold_mu : inc_hot_hi, ~ .x / mean_fitness2)) %>%
                  dplyr::mutate(across(nes_cold_mu : nes_hot_hi, ~ .x / mean_fitness_hatched2))
          
          one_sp_table <- one_sp_table[,]
  
      saveRDS(one_sp_table, here::here("2_modified_data", "puma_table.rds"))
          
          one_sp_table2 <- data.frame(lat_band = rep(one_sp_table$lat_band, 2),
                                      inc_mu = c(one_sp_table$inc_cold_mu, one_sp_table$inc_hot_mu),
                                      inc_lo = c(one_sp_table$inc_cold_lo, one_sp_table$inc_hot_lo),
                                      inc_hi = c(one_sp_table$inc_cold_hi, one_sp_table$inc_hot_hi),
                                      nes_mu = c(one_sp_table$nes_cold_mu, one_sp_table$nes_hot_mu),
                                      nes_lo = c(one_sp_table$nes_cold_lo, one_sp_table$nes_hot_lo),
                                      nes_hi = c(one_sp_table$nes_cold_hi, one_sp_table$nes_hot_hi),
                                      cat = c(rep("cold", nrow(one_sp_table)), rep("hot", nrow(one_sp_table))),
                                      dodger = c(rep(0.15, nrow(one_sp_table)), rep(-0.15, nrow(one_sp_table))))
          one_sp_table2$inc_sig <- "no"
          one_sp_table2$nes_sig <- "no"
          for(i in 1:nrow(one_sp_table2)){
            if(one_sp_table2$inc_hi[i] < 1){one_sp_table2$inc_sig[i] <- "yes"}
            if(one_sp_table2$inc_lo[i] > 1){one_sp_table2$inc_sig[i] <- "yes"}
            
            if(one_sp_table2$nes_hi[i] < 1){one_sp_table2$nes_sig[i] <- "yes"}
            if(one_sp_table2$nes_lo[i] > 1){one_sp_table2$nes_sig[i] <- "yes"}
          }
          puma_p2 <- ggplot(data = one_sp_table2, mapping = aes(x = inc_mu, y = lat_band, color = cat, shape = inc_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = inc_lo, xend = inc_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(21, 16)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "C", size = 6) +
            ggtitle("Incubation sensitivity to \n 2 SD cold or heat")
            
          puma_p3 <- ggplot(data = one_sp_table2, mapping = aes(x = nes_mu, y = lat_band, color = cat, shape = nes_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = nes_lo, xend = nes_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(21, 16)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "D", size = 6) +
            ggtitle("Provisioning sensitivity to \n 2 SD cold or heat")
          
          p_combo <- ggarrange(puma_p1, puma_p2, puma_p3, nrow = 1)
          ggsave(here::here("4_output_figures", "puma_latitude.svg"), plot = p_combo, device = "svg",
                 width = 7.6, height = 4.6, units = "in")
          print(p_combo)




```

```{r eabl-only, message = FALSE, warning = FALSE, echo = FALSE}
# make a map of breeding timing

    # subset the summarized data to one species or one plot group
        s_sub <- subset(n_summary, n_summary$species_code == "easblu")
        grid_s <- st_join(grid, s_sub, join = st_intersects)
        grid_s <- subset(grid_s, grid_s$n > 10)
      
      # Make a figure for lay date, clutch size, fledged number, and fledge y/n for that species
          p_lay_eabl <- p_base + geom_sf(data = grid_s, mapping = aes(fill = lay)) + ggtitle("Eastern Bluebird") +
            coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], 3300000)) +
            scale_fill_viridis(alpha = 0.8, guide = guide_colorbar(title = "Laying day \n of year")) +
            annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "A", fontface = 2)
          
  
        ggsave(here::here("4_output_figures", "eabl_map.svg"), plot = p_lay_eabl, device = "svg",
               units = "in", width = 5.9, height = 3.4)
            

          
# split by latitude          
  ## Analyses with individual species
          one_sp <- subset(dsfo_std, dsfo_std$alpha4 == "EABL")

    # create a factor level with equal samples split by longitude
          splits <- 5 # how many bands to make
          one_sp <- one_sp %>%
            arrange(c_lat) %>%
            mutate(lat_band = ntile(c_lat, splits))
          one_sp$lat_band <- as.factor(one_sp$lat_band)
      # recalculate sd of temperature for each band
          one_sp$s_min_3_inc2 <- transform(one_sp, s_min_3_inc2 = ave(min_3_inc, lat_band, FUN = scale))$s_min_3_inc2
          one_sp$s_max_3_inc2 <- transform(one_sp, s_max_3_inc2 = ave(max_3_inc, lat_band, FUN = scale))$s_max_3_inc2
          one_sp$s_min_3_nes2 <- transform(one_sp, s_min_3_nes2 = ave(min_3_nes, lat_band, FUN = scale))$s_min_3_nes2
          one_sp$s_max_3_nes2 <- transform(one_sp, s_max_3_nes2 = ave(max_3_nes, lat_band, FUN = scale))$s_max_3_nes2
          
          
          one_spn <- subset(one_sp, one_sp$mean_chicks > 0)
          one_sp2 <- one_sp %>%
            pivot_longer(cols = c("min_3_all", "max_3_all"), values_to = "temperature", names_to = "category")
   
    # recalculate relative fitness for each band
            rel_one <- one_sp %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness2 = mean(mean_fledge))
          
          one_sp <- plyr::join(one_sp, rel_one, "lat_band", "left", "first")
          one_sp$w_fitness2 <- one_sp$mean_fledge / one_sp$mean_fitness2
          
          rel_one2 <- one_spn %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness_hatched2 = mean(mean_fledge))
          
          one_spn <- plyr::join(one_spn, rel_one2, "lat_band", "left", "first")
          one_spn$w_fitness_b2 <- one_spn$mean_fledge / one_spn$mean_fitness_hatched2
          
      # manipulating to get the range of latitudes in each band in degree projection    
          one_sp_o <- one_sp %>%
            st_as_sf(coords = c("c_long", "c_lat"), crs = proj_code) %>%
            st_transform(crs = crs(namer_o))
          
          one_sp_o$c_lat <- st_coordinates(one_sp_o)[, 2]
          one_sp_o$c_long <- st_coordinates(one_sp_o)[, 1]
          
          one_sp_o2 <- one_sp_o %>%
            st_drop_geometry() %>%
            arrange(c_lat) %>%
            dplyr::mutate(lat_band2 = ntile(c_lat, splits))
          one_sp_o2$lat_band2 <- as.factor(one_sp_o2$lat_band2)
          
          xx <- one_sp_o2 %>%
            dplyr::group_by(lat_band2) %>%
            dplyr::summarise(min = min(c_lat), max = max(c_lat), n = n())
          
    # plots    

          eabl_p1 <- ggplot(one_sp2, mapping = aes(x = temperature, y = lat_band, fill = category)) +
            geom_boxplot(outlier.shape = NA, alpha = 0.7) +
            guides(fill = "none", color = "none") +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 12), axis.title = element_text(size = 14),
              plot.title = element_text(hjust = 0.5)) +
            scale_fill_manual(values = c("coral3", "slateblue")) +
            ylab("") +
            xlab("Degrees C") +
            coord_cartesian(ylim = c(1, 5)) +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B", size = 6) +
            ggtitle("3-day temperature extremes \n in full nesting cycle") +
            ylab("Latitude band (equal samples)") +
            theme(axis.text.y = element_blank())
          
          levs <- levels(one_sp$lat_band)
          incmods <- list(NA)
          nesmods <- list(NA)
          one_sp_table <- data.frame(inc_cold_mu = rep(NA, splits), inc_cold_lo = NA, inc_cold_hi = NA,
                                   inc_hot_mu = NA,  inc_hot_lo = NA, inc_hot_hi = NA,
                                   nes_cold_mu = NA, nes_cold_lo = NA, nes_cold_hi = NA,
                                   nes_hot_mu = NA, nes_hot_lo = NA, nes_hot_hi = NA,
                                   lat_band = seq(1, splits))
          
          one_sp$stn_id2 <- as.factor(one_sp$stn_id)
          
          for(i in 1:splits){
            tem_dat <- one_sp[one_sp$lat_band == levs[i], ]
            spatial_k <- floor(length(levels(as.factor(tem_dat$stn_id))) * 0.75)
            
            minc1 <- gam(mean_fledge ~ s(s_min_3_inc2) + s(s_max_3_inc2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k), data = tem_dat)
          
            mnes1 <- gam(mean_fledge ~ s(s_min_3_nes2) + s(s_max_3_nes2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k), data = tem_dat)
            
            incmods[[i]] <- minc1
            nesmods[[i]] <- mnes1
          }
          
          
            saveRDS(incmods, here::here("6_saved_data_objects", "eabl_incmods.rds"))
            saveRDS(nesmods, here::here("6_saved_data_objects", "eabl_nesmods.rds"))
          
            for(i in 1:nrow(one_sp_table)){
            p1 <- get_gam_predictions2(nesmods[[i]], s_min_3_nes2, series_jump = 1)
            p1b <- subset(p1, p1$s_min_3_nes2 == -2)[1, ]
            one_sp_table$nes_cold_mu[i] <- p1b$mean_fledge[1]
            one_sp_table$nes_cold_lo[i] <- p1b$CI_lower[1]
            one_sp_table$nes_cold_hi[i] <- p1b$CI_upper[1]
            
            p2 <- get_gam_predictions2(nesmods[[i]], s_max_3_nes2, series_jump = 1)
            p2b <- subset(p2, p2$s_max_3_nes2 == 2)[1, ]
            one_sp_table$nes_hot_mu[i] <- p2b$mean_fledge[1]
            one_sp_table$nes_hot_lo[i] <- p2b$CI_lower[1]
            one_sp_table$nes_hot_hi[i] <- p2b$CI_upper[1]
            
            p3 <- get_gam_predictions2(incmods[[i]], s_min_3_inc2, series_jump = 1)
            p3b <- subset(p3, p3$s_min_3_inc2 == -2)[1, ]
            one_sp_table$inc_cold_mu[i] <- p3b$mean_fledge[1]
            one_sp_table$inc_cold_lo[i] <- p3b$CI_lower[1]
            one_sp_table$inc_cold_hi[i] <- p3b$CI_upper[1]
            
            p4 <- get_gam_predictions2(incmods[[i]], s_max_3_inc2, series_jump = 1)
            p4b <- subset(p4, p4$s_max_3_inc2 == 2)[1, ]
            one_sp_table$inc_hot_mu[i] <- p4b$mean_fledge[1]
            one_sp_table$inc_hot_lo[i] <- p4b$CI_lower[1]
            one_sp_table$inc_hot_hi[i] <- p4b$CI_upper[1]
            
          }
            
          #one_sp_table <- cbind(apply(one_sp_table[1:12], FUN=function(x) exp(x), MARGIN=2), one_sp_table[13])
  
          one_sp_table <- merge(rel_one2, one_sp_table, id=c("lat_band"))
          
          one_sp_table <- merge(rel_one, one_sp_table, id=c("lat_band"))
  
          one_sp_table <- one_sp_table %>%
                  dplyr::mutate(across(inc_cold_mu : inc_hot_hi, ~ .x / mean_fitness2)) %>%
                  dplyr::mutate(across(nes_cold_mu : nes_hot_hi, ~ .x / mean_fitness_hatched2))
          
          one_sp_table <- one_sp_table[,]
  
          
          saveRDS(one_sp_table, here::here("2_modified_data", "eabl_table.rds"))
          
          one_sp_table2 <- data.frame(lat_band = rep(one_sp_table$lat_band, 2),
                                      inc_mu = c(one_sp_table$inc_cold_mu, one_sp_table$inc_hot_mu),
                                      inc_lo = c(one_sp_table$inc_cold_lo, one_sp_table$inc_hot_lo),
                                      inc_hi = c(one_sp_table$inc_cold_hi, one_sp_table$inc_hot_hi),
                                      nes_mu = c(one_sp_table$nes_cold_mu, one_sp_table$nes_hot_mu),
                                      nes_lo = c(one_sp_table$nes_cold_lo, one_sp_table$nes_hot_lo),
                                      nes_hi = c(one_sp_table$nes_cold_hi, one_sp_table$nes_hot_hi),
                                      cat = c(rep("cold", nrow(one_sp_table)), rep("hot", nrow(one_sp_table))),
                                      dodger = c(rep(0.15, nrow(one_sp_table)), rep(-0.15, nrow(one_sp_table))))
          one_sp_table2$inc_sig <- "no"
          one_sp_table2$nes_sig <- "no"
          
          for(i in 1:nrow(one_sp_table2)){
            if(one_sp_table2$inc_hi[i] < 1){one_sp_table2$inc_sig[i] <- "yes"}
            if(one_sp_table2$inc_lo[i] > 1){one_sp_table2$inc_sig[i] <- "yes"}
            
            if(one_sp_table2$nes_hi[i] < 1){one_sp_table2$nes_sig[i] <- "yes"}
            if(one_sp_table2$nes_lo[i] > 1){one_sp_table2$nes_sig[i] <- "yes"}
          }
          
      # plot    
          eabl_p2 <- ggplot(data = one_sp_table2, mapping = aes(x = inc_mu, y = lat_band, color = cat, shape = inc_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = inc_lo, xend = inc_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(21, 16)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "C", size = 6) +
            ggtitle("Incubation sensitivity to \n 2 SD cold or heat")
            
          eabl_p3 <- ggplot(data = one_sp_table2, mapping = aes(x = nes_mu, y = lat_band, color = cat, shape = nes_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = nes_lo, xend = nes_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(16, 21)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "D", size = 6) +
            ggtitle("Provisioning sensitivity to \n 2 SD cold or heat")
          
        p_combo_eabl <- ggarrange(eabl_p1, eabl_p2, eabl_p3, nrow = 1)
          ggsave(here::here("4_output_figures", "eabl_latitude.svg"), plot = p_combo_eabl, device = "svg",
                 width = 7.6, height = 4.6, units = "in")
          print(p_combo_eabl)




```

```{r tres-only, message = FALSE, warning = FALSE, echo = FALSE}
# make a map of breeding timing

    # subset the summarized data to one species or one plot group
        s_sub <- subset(n_summary, n_summary$species_code == "treswa")
        grid_s <- st_join(grid, s_sub, join = st_intersects)
        grid_s <- subset(grid_s, grid_s$n > 10)
      
      # Make a figure for lay date, clutch size, fledged number, and fledge y/n for that species
          p_lay_tres <- p_base + geom_sf(data = grid_s, mapping = aes(fill = lay)) + ggtitle("Tree Swallow") +
            coord_sf(crs = proj_code, xlim = c(bb["xmin"], bb["xmax"]), ylim = c(bb["ymin"], 3300000)) +
            scale_fill_viridis(alpha = 0.8, guide = guide_colorbar(title = "Laying day \n of year")) +
            annotate("text", x = -Inf, y = -Inf, hjust = -0.7, vjust = -1, label = "A", fontface = 2)
          
  
        ggsave(here::here("4_output_figures", "tres_map.svg"), plot = p_lay_tres, device = "svg",
               units = "in", width = 5.9, height = 3.4)
            

          
# split by latitude          
  ## Analyses with individual species
          one_sp <- subset(dsfo_std, dsfo_std$alpha4 ==  "TRES")
          
      
    # create a factor level with equal samples split by longitude
          splits <- 5 # how many bands to make
          one_sp <- one_sp %>%
            arrange(c_lat) %>%
            mutate(lat_band = ntile(c_lat, splits))
          one_sp$lat_band <- as.factor(one_sp$lat_band)
      # recalculate sd of temperature for each band
          one_sp$s_min_3_inc2 <- transform(one_sp, s_min_3_inc2 = ave(min_3_inc, lat_band, FUN = scale))$s_min_3_inc2
          one_sp$s_max_3_inc2 <- transform(one_sp, s_max_3_inc2 = ave(max_3_inc, lat_band, FUN = scale))$s_max_3_inc2
          one_sp$s_min_3_nes2 <- transform(one_sp, s_min_3_nes2 = ave(min_3_nes, lat_band, FUN = scale))$s_min_3_nes2
          one_sp$s_max_3_nes2 <- transform(one_sp, s_max_3_nes2 = ave(max_3_nes, lat_band, FUN = scale))$s_max_3_nes2
          
          
          one_spn <- subset(one_sp, one_sp$mean_chicks > 0)
          one_sp2 <- one_sp %>%
            pivot_longer(cols = c("min_3_all", "max_3_all"), values_to = "temperature", names_to = "category")
        
          
          
    # recalculate relative fitness for each band
            rel_one <- one_sp %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness2 = mean(mean_fledge))
          
          one_sp <- plyr::join(one_sp, rel_one, "lat_band", "left", "first")
          one_sp$w_fitness2 <- one_sp$mean_fledge / one_sp$mean_fitness2
          
          rel_one2 <- one_spn %>%
            dplyr::group_by(lat_band) %>%
            dplyr::summarise(mean_fitness_hatched2 = mean(mean_fledge))
          
          one_spn <- plyr::join(one_spn, rel_one2, "lat_band", "left", "first")
          one_spn$w_fitness_b2 <- one_spn$mean_fledge / one_spn$mean_fitness_hatched2
          
          
     # manipulating to get the range of latitudes in each band in degree projection    
          one_sp_o <- one_sp %>%
            st_as_sf(coords = c("c_long", "c_lat"), crs = proj_code) %>%
            st_transform(crs = crs(namer_o))
          
          one_sp_o$c_lat <- st_coordinates(one_sp_o)[, 2]
          one_sp_o$c_long <- st_coordinates(one_sp_o)[, 1]
          
          one_sp_o2 <- one_sp_o %>%
            st_drop_geometry() %>%
            arrange(c_lat) %>%
            dplyr::mutate(lat_band2 = ntile(c_lat, splits))
          one_sp_o2$lat_band2 <- as.factor(one_sp_o2$lat_band2)
          
          xx <- one_sp_o2 %>%
            dplyr::group_by(lat_band2) %>%
            dplyr::summarise(min = min(c_lat), max = max(c_lat), n = n())      
          
    # plots    

          tres_p1 <- ggplot(one_sp2, mapping = aes(x = temperature, y = lat_band, fill = category)) +
            geom_boxplot(outlier.shape = NA, alpha = 0.7) +
            guides(fill = "none", color = "none") +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 12), axis.title = element_text(size = 14),
              plot.title = element_text(hjust = 0.5)) +
            scale_fill_manual(values = c("coral3", "slateblue")) +
            ylab("") +
            xlab("Degrees C") +
            coord_cartesian(xlim = c(8, 41), ylim = c(1, 5)) +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "B", size = 6) +
            ggtitle("3-day temperature extremes \n in full nesting cycle") +
            ylab("Latitude band (equal samples)") +
            theme(axis.text.y = element_blank())
          
         levs <- levels(one_sp$lat_band)
          incmods <- list(NA)
          nesmods <- list(NA)
          one_sp_table <- data.frame(inc_cold_mu = rep(NA, splits), inc_cold_lo = NA, inc_cold_hi = NA,
                                   inc_hot_mu = NA,  inc_hot_lo = NA, inc_hot_hi = NA,
                                   nes_cold_mu = NA, nes_cold_lo = NA, nes_cold_hi = NA,
                                   nes_hot_mu = NA, nes_hot_lo = NA, nes_hot_hi = NA,
                                   lat_band = seq(1, splits))
          
          for(i in 1:splits){
            tem_dat <- one_sp[one_sp$lat_band == levs[i], ]
            spatial_k <- floor(length(levels(as.factor(tem_dat$stn_id))) * 0.75)
            
            minc1 <- gam(mean_fledge ~ s(s_min_3_inc2) + s(s_max_3_inc2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k), data = one_sp[one_sp$lat_band == levs[i], ])
          
            mnes1 <- gam(mean_fledge ~ s(s_min_3_nes2) + s(s_max_3_nes2) + s(hatch_doy) + s(year) +
                           s(c_long, c_lat, k=spatial_k), data = one_spn[one_spn$lat_band == levs[i], ])
            
            incmods[[i]] <- minc1
            nesmods[[i]] <- mnes1
          }
          
            saveRDS(incmods, here::here("6_saved_data_objects", "tres_incmods.rds"))
            saveRDS(nesmods, here::here("6_saved_data_objects", "tres_nesmods.rds"))
          
                for(i in 1:nrow(one_sp_table)){
            p1 <- get_gam_predictions2(nesmods[[i]], s_min_3_nes2, series_jump = 1)
            p1b <- subset(p1, p1$s_min_3_nes == -2)[1, ]
            one_sp_table$nes_cold_mu[i] <- p1b$mean_fledge[1]
            one_sp_table$nes_cold_lo[i] <- p1b$CI_lower[1]
            one_sp_table$nes_cold_hi[i] <- p1b$CI_upper[1]
            
            p2 <- get_gam_predictions2(nesmods[[i]], s_max_3_nes2, series_jump = 1)
            p2b <- subset(p2, p2$s_max_3_nes == 2)[1, ]
            one_sp_table$nes_hot_mu[i] <- p2b$mean_fledge[1]
            one_sp_table$nes_hot_lo[i] <- p2b$CI_lower[1]
            one_sp_table$nes_hot_hi[i] <- p2b$CI_upper[1]
            
            p3 <- get_gam_predictions2(incmods[[i]], s_min_3_inc2, series_jump = 1)
            p3b <- subset(p3, p3$s_min_3_inc == -2)[1, ]
            one_sp_table$inc_cold_mu[i] <- p3b$mean_fledge[1]
            one_sp_table$inc_cold_lo[i] <- p3b$CI_lower[1]
            one_sp_table$inc_cold_hi[i] <- p3b$CI_upper[1]
            
            p4 <- get_gam_predictions2(incmods[[i]], s_max_3_inc2, series_jump = 1)
            p4b <- subset(p4, p4$s_max_3_inc == 2)[1, ]
            one_sp_table$inc_hot_mu[i] <- p4b$mean_fledge[1]
            one_sp_table$inc_hot_lo[i] <- p4b$CI_lower[1]
            one_sp_table$inc_hot_hi[i] <- p4b$CI_upper[1]
          }
            
          #one_sp_table <- cbind(apply(one_sp_table[1:12], FUN=function(x) exp(x), MARGIN=2), one_sp_table[13])
  
          one_sp_table <- merge(rel_one2, one_sp_table, id=c("lat_band"))
          
          one_sp_table <- merge(rel_one, one_sp_table, id=c("lat_band"))
  
          one_sp_table <- one_sp_table %>%
                  mutate(across(inc_cold_mu : inc_hot_hi, ~ .x / mean_fitness2)) %>%
                  mutate(across(nes_cold_mu : nes_hot_hi, ~ .x / mean_fitness_hatched2))
          
          one_sp_table <- one_sp_table[,]
  
          
          saveRDS(one_sp_table, here::here("2_modified_data", "tres_table.rds"))
          
          one_sp_table2 <- data.frame(lat_band = rep(one_sp_table$lat_band, 2),
                                      inc_mu = c(one_sp_table$inc_cold_mu, one_sp_table$inc_hot_mu),
                                      inc_lo = c(one_sp_table$inc_cold_lo, one_sp_table$inc_hot_lo),
                                      inc_hi = c(one_sp_table$inc_cold_hi, one_sp_table$inc_hot_hi),
                                      nes_mu = c(one_sp_table$nes_cold_mu, one_sp_table$nes_hot_mu),
                                      nes_lo = c(one_sp_table$nes_cold_lo, one_sp_table$nes_hot_lo),
                                      nes_hi = c(one_sp_table$nes_cold_hi, one_sp_table$nes_hot_hi),
                                      cat = c(rep("cold", nrow(one_sp_table)), rep("hot", nrow(one_sp_table))),
                                      dodger = c(rep(0.15, nrow(one_sp_table)), rep(-0.15, nrow(one_sp_table))))
          one_sp_table2$inc_sig <- "no"
          one_sp_table2$nes_sig <- "no"
          for(i in 1:nrow(one_sp_table2)){
            if(one_sp_table2$inc_hi[i] < 1){one_sp_table2$inc_sig[i] <- "yes"}
            if(one_sp_table2$inc_lo[i] > 1){one_sp_table2$inc_sig[i] <- "yes"}
            
            if(one_sp_table2$nes_hi[i] < 1){one_sp_table2$nes_sig[i] <- "yes"}
            if(one_sp_table2$nes_lo[i] > 1){one_sp_table2$nes_sig[i] <- "yes"}
          }
          
      # plot    
          tres_p2 <- ggplot(data = one_sp_table2, mapping = aes(x = inc_mu, y = lat_band, color = cat, shape = inc_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = inc_lo, xend = inc_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(21, 16)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "C", size = 6) +
            ggtitle("Incubation sensitivity to \n 2 SD cold or heat")
            
          tres_p3 <- ggplot(data = one_sp_table2, mapping = aes(x = nes_mu, y = lat_band, color = cat, shape = nes_sig)) +
            geom_vline(xintercept = 1, linetype = "dashed", color = "gray25") +
            geom_segment(mapping = aes(x = nes_lo, xend = nes_hi, y = lat_band, yend = lat_band),
                         position = position_nudge(y = one_sp_table2$dodger)) +
            geom_point(position = position_nudge(y = one_sp_table2$dodger), size = 2.5, fill = "white") +
            scale_color_manual(values = c("slateblue", "coral3")) +
            theme_bw() +
            theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),
              axis.text = element_text(size = 14), axis.title = element_text(size = 14),
              axis.text.y = element_blank(), plot.title = element_text(hjust = 0.5)) +
            coord_cartesian(xlim = c(0.7, 1.1), ylim = c(0.7, 5.3)) +
            xlab("Relative fitness") +
            scale_shape_manual(values = c(21, 16)) +
            guides(shape = "none", color = "none") +
            ylab("") +
            annotate("text", x = -Inf, y = Inf, hjust = -0.7, vjust = 1.5, label = "D", size = 6) +
            ggtitle("Provisioning sensitivity to \n 2 SD cold or heat")
          
          
          


          
          
          
          
          p_combo_tres <- ggarrange(tres_p1, tres_p2, tres_p3, nrow = 1)
          ggsave(here::here("4_output_figures", "tres_latitude.svg"), plot = p_combo_tres, device = "svg",
                 width = 7.6, height = 4.6, units = "in")
          print(p_combo_tres)
```





